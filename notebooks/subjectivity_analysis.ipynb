{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "import time\n",
    "import nltk\n",
    "from textblob.en import sentiment as pattern_sentiment\n",
    "from textblob.en.sentiments import PatternAnalyzer as pattern_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/phanivalasa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/phanivalasa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../data/raw/tweetsCID_cosine_bow.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80467 entries, 0 to 80466\n",
      "Data columns (total 11 columns):\n",
      "tweet_id                             80433 non-null object\n",
      "tweet_text                           80403 non-null object\n",
      "user_id                              80369 non-null object\n",
      "tweet_time                           80335 non-null object\n",
      "no_favs                              80335 non-null object\n",
      "no_retweets                          80335 non-null object\n",
      "urls                                 80335 non-null object\n",
      "content_id                           80335 non-null object\n",
      "tweet_text_url_token                 80301 non-null object\n",
      "tweet_urls                           80301 non-null object\n",
      "tweet_text_url_token_preprocessed    80301 non-null object\n",
      "dtypes: object(11)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets[65500:65530]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textblob subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_tuples(input):\n",
    "    ret_list = []\n",
    "    ret_string = ''\n",
    "    for i in range(len(input)):\n",
    "        if input[i][1] == 0:\n",
    "            tpl = (\" \".join(input[i][0]), input[i][1])\n",
    "            ret_list.append(tpl)\n",
    "#         ret_string = ret_string+str(tpl)\n",
    "        \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_tuples(input):\n",
    "    ret_list = []\n",
    "    ret_string = ''\n",
    "    for i in range(len(input)):\n",
    "        if input[i][1] != 0:\n",
    "            tpl = (\" \".join(input[i][0]), input[i][1])\n",
    "            ret_list.append(tpl)\n",
    "#         ret_string = ret_string+str(tpl)\n",
    "        \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets_textblob(df):    \n",
    "    column_names = ['tweet_id','content_id','tweet_text_url_token','polarity_score', 'sentiment','subjective',\n",
    "                    'sub_assessments','obj_assessments']\n",
    "    # polarity_score - is the polarity score\n",
    "    # sentiment - pos, neg or neu\n",
    "    # subjective - True/False. True if it's neg or pos.\n",
    "    # sub_assessments - words contributing to pos/neg\n",
    "\n",
    "    return_df = pd.DataFrame()\n",
    "    for idx,row in df.iterrows():\n",
    "        tweet_id = row['tweet_id']\n",
    "        content_id = row['content_id']\n",
    "        tweet_text_url_token = row['tweet_text_url_token']\n",
    "#         sub = TextBlob(row['tweet_text_url_token']).sentiment.subjectivity\n",
    "        polarity_score = TextBlob(str(row['tweet_text_url_token'])).sentiment.polarity\n",
    "        if (polarity_score>0):\n",
    "            sentiment = 'pos'\n",
    "            subjective = True\n",
    "        elif (polarity_score<0):\n",
    "            sentiment = 'neg'\n",
    "            subjective = True\n",
    "        else:\n",
    "            sentiment = 'neu'\n",
    "            subjective = False\n",
    "        sub_assessments = sub_tuples(pattern_sentiment(row['tweet_text_url_token']).assessments)\n",
    "        obj_assessments = obj_tuples(pattern_sentiment(row['tweet_text_url_token']).assessments)\n",
    "        return_df = pd.concat([return_df, pd.DataFrame([[tweet_id,content_id,tweet_text_url_token,polarity_score,sentiment,\n",
    "                                                         subjective, sub_assessments,obj_assessments]])],axis=0)\n",
    "    \n",
    "    return_df.columns=column_names\n",
    "    return_df.index =return_df['tweet_id']\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet = tweets[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80467"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = process_tweets_textblob(df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjective Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>2736</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(ecological, 0.4)]</td>\n",
       "      <td>[(financial, 0.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.10000000000000002)]</td>\n",
       "      <td>[(not actually, -0.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(horrible, -1.0)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61559E+17</td>\n",
       "      <td>How an elephant tranquilizer became the latest deadly drug in the opioid epidemic &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(latest, 0.5), (deadly, -0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61566E+17</td>\n",
       "      <td>\"When it comes to cracking down on opioids, just going after the drug’s supply isn’t enough.\" &lt;URL&gt; by @germanrlopez</td>\n",
       "      <td>1909</td>\n",
       "      <td>-0.077778</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(down, -0.15555555555555559)]</td>\n",
       "      <td>[(enough, 0.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.6157E+17</td>\n",
       "      <td>Very real news. If you can (literally) even physically see the amount of this you are taking, it's enough to kill you &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(very real, 0.26)]</td>\n",
       "      <td>[(physically, 0.0), (enough, 0.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61574E+17</td>\n",
       "      <td>Crack down on opiods and heroin and people start using horse tranquilizers. You have to provide treatment to help. &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(down, -0.15555555555555559)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61575E+17</td>\n",
       "      <td>Another article that can't keep prescription vs illegal opioid use straight. Too bad, @voxdotcom-could've been good  &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(illegal, -0.5), (straight, 0.2), (bad, -0.6999999999999998), (good, 0.7)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61586E+17</td>\n",
       "      <td>Veterinary tranquilizer one of latest deadly drug in the opioid epidemic #veterinary @whcucdavis &lt;URL&gt; via @voxdotcom</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(latest, 0.5), (deadly, -0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61665E+17</td>\n",
       "      <td>Drugs like fentanyl and carfentanil are becoming more common in America’s deadly drug crisis. \\n&lt;URL&gt; &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(becoming, 0.45), (more, 0.5), (common, -0.3), (deadly, -0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61742E+17</td>\n",
       "      <td>@tminus5 \"Fentanyl will require unique solutions\" &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(unique, 0.375)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61953E+17</td>\n",
       "      <td>Failure of supply side tactics &amp;amp; call for Rx heroin: How elephant tranq became latest deadly drug &lt;URL&gt; via @voxdotcom</td>\n",
       "      <td>1909</td>\n",
       "      <td>-0.005556</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(failure, -0.3166666666666667), (latest, 0.5), (deadly, -0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62678E+17</td>\n",
       "      <td>Very good @juliaoftoronto piece on what scientists have learned about the causes of autism: &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(very good, 0.9099999999999999)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62681E+17</td>\n",
       "      <td>\"They've ditched the vaccine theory\" is a very weird way to refer to something that was not at all scientific consensus, at any point, ever &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>-0.650000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(very weird, -0.65)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62684E+17</td>\n",
       "      <td>When will antivacs admit they're flat-out wrong? #Vaccinesdonotcauseautism. Debunked yrs ago. Meanwhile, these folks causing health crisis. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(wrong, -0.5)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62685E+17</td>\n",
       "      <td>Pre-#IMFAR2017, a round-up of some of the latest science on what might lead to autism. Spoiler: not vaccines. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(latest, 0.5)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62685E+17</td>\n",
       "      <td>What causes autism? @juliaoftoronto talked to leading researchers about their latest and most compelling theories &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(latest, 0.5), (most, 0.5), (compelling, 0.3)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62699E+17</td>\n",
       "      <td>Helps clear some things up. Please read and share. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.10000000000000002)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62721E+17</td>\n",
       "      <td>Interesting read on the state of autism research, what's known to contribute to risk, etc. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(interesting, 0.5)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62729E+17</td>\n",
       "      <td>I've got this one - autism is genetic. It's caused by mutations in the DNA. It's really quite well understood: &lt;URL&gt; &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(really, 0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62733E+17</td>\n",
       "      <td>Let's move on and find the real cause of #autism. #vaxxed #vaccineswork #wedid\\n&lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(real, 0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62795E+17</td>\n",
       "      <td>“Of all the causes of autism, the thing we know with the greatest certainty is that it’s a very genetic disorder,” &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(greatest, 1.0), (very, 0.2)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62798E+17</td>\n",
       "      <td>Great article. #autismawareness #autismspeaks &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(great, 0.8)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62802E+17</td>\n",
       "      <td>If 1 in 68 kids are diagnosed with Autism, do you realize what this means?  It means many of them DON'T HAVE IT. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(many, 0.5)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62826E+17</td>\n",
       "      <td>Exciting research is being done; Think I need to get my genetics text out to grasp it all, but so grateful to those working for answers. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(exciting, 0.3)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62827E+17</td>\n",
       "      <td>that's a terrible title &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(terrible, -1.0)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62834E+17</td>\n",
       "      <td>\"After hundreds and hundreds of studies in thousands of children\" ... &amp;lt;amateurish statement lacking scientific process &amp;amp; direct evidence&amp;gt; &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(direct, 0.1)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62866E+17</td>\n",
       "      <td>\"autism is much more genetic, with well over 100 genes now implicated. \" &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(much more, 0.5), (implicated, -0.4)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62889E+17</td>\n",
       "      <td>Very interesting reading &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(very interesting, 0.65)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62909E+17</td>\n",
       "      <td>The dearth of iron-clad autism triggers may be why parents are vulnerable to the autism-vaccine theory. &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(vulnerable, -0.5)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                                 \n",
       "8.51485E+17                                                                      #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.55009E+17                                           The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "8.55012E+17                     (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "8.61559E+17                                                                    How an elephant tranquilizer became the latest deadly drug in the opioid epidemic <URL>   \n",
       "8.61566E+17                                       \"When it comes to cracking down on opioids, just going after the drug’s supply isn’t enough.\" <URL> by @germanrlopez   \n",
       "8.6157E+17                                 Very real news. If you can (literally) even physically see the amount of this you are taking, it's enough to kill you <URL>   \n",
       "8.61574E+17                                   Crack down on opiods and heroin and people start using horse tranquilizers. You have to provide treatment to help. <URL>   \n",
       "8.61575E+17                                 Another article that can't keep prescription vs illegal opioid use straight. Too bad, @voxdotcom-could've been good  <URL>   \n",
       "8.61586E+17                                      Veterinary tranquilizer one of latest deadly drug in the opioid epidemic #veterinary @whcucdavis <URL> via @voxdotcom   \n",
       "8.61665E+17                                                Drugs like fentanyl and carfentanil are becoming more common in America’s deadly drug crisis. \\n<URL> <URL>   \n",
       "8.61742E+17                                                                                                    @tminus5 \"Fentanyl will require unique solutions\" <URL>   \n",
       "8.61953E+17                                 Failure of supply side tactics &amp; call for Rx heroin: How elephant tranq became latest deadly drug <URL> via @voxdotcom   \n",
       "8.62678E+17                                                          Very good @juliaoftoronto piece on what scientists have learned about the causes of autism: <URL>   \n",
       "8.62681E+17          \"They've ditched the vaccine theory\" is a very weird way to refer to something that was not at all scientific consensus, at any point, ever <URL>   \n",
       "8.62684E+17          When will antivacs admit they're flat-out wrong? #Vaccinesdonotcauseautism. Debunked yrs ago. Meanwhile, these folks causing health crisis. <URL>   \n",
       "8.62685E+17                                        Pre-#IMFAR2017, a round-up of some of the latest science on what might lead to autism. Spoiler: not vaccines. <URL>   \n",
       "8.62685E+17                                    What causes autism? @juliaoftoronto talked to leading researchers about their latest and most compelling theories <URL>   \n",
       "8.62699E+17                                                                                                   Helps clear some things up. Please read and share. <URL>   \n",
       "8.62721E+17                                                           Interesting read on the state of autism research, what's known to contribute to risk, etc. <URL>   \n",
       "8.62729E+17                                 I've got this one - autism is genetic. It's caused by mutations in the DNA. It's really quite well understood: <URL> <URL>   \n",
       "8.62733E+17                                                                      Let's move on and find the real cause of #autism. #vaxxed #vaccineswork #wedid\\n<URL>   \n",
       "8.62795E+17                                   “Of all the causes of autism, the thing we know with the greatest certainty is that it’s a very genetic disorder,” <URL>   \n",
       "8.62798E+17                                                                                                        Great article. #autismawareness #autismspeaks <URL>   \n",
       "8.62802E+17                                     If 1 in 68 kids are diagnosed with Autism, do you realize what this means?  It means many of them DON'T HAVE IT. <URL>   \n",
       "8.62826E+17             Exciting research is being done; Think I need to get my genetics text out to grasp it all, but so grateful to those working for answers. <URL>   \n",
       "8.62827E+17                                                                                                                              that's a terrible title <URL>   \n",
       "8.62834E+17  \"After hundreds and hundreds of studies in thousands of children\" ... &lt;amateurish statement lacking scientific process &amp; direct evidence&gt; <URL>   \n",
       "8.62866E+17                                                                             \"autism is much more genetic, with well over 100 genes now implicated. \" <URL>   \n",
       "8.62889E+17                                                                                                                             Very interesting reading <URL>   \n",
       "8.62909E+17                                              The dearth of iron-clad autism triggers may be why parents are vulnerable to the autism-vaccine theory. <URL>   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective  \\\n",
       "tweet_id                                                       \n",
       "8.51485E+17       2736        0.200000       pos        True   \n",
       "8.55009E+17       2644        0.050000       pos        True   \n",
       "8.55012E+17       2644       -1.000000       neg        True   \n",
       "8.61559E+17       1909        0.150000       pos        True   \n",
       "8.61566E+17       1909       -0.077778       neg        True   \n",
       "8.6157E+17        1909        0.086667       pos        True   \n",
       "8.61574E+17       1909       -0.155556       neg        True   \n",
       "8.61575E+17       1909       -0.075000       neg        True   \n",
       "8.61586E+17       1909        0.150000       pos        True   \n",
       "8.61665E+17       1909        0.112500       pos        True   \n",
       "8.61742E+17       1909        0.375000       pos        True   \n",
       "8.61953E+17       1909       -0.005556       neg        True   \n",
       "8.62678E+17       2795        0.910000       pos        True   \n",
       "8.62681E+17       2795       -0.650000       neg        True   \n",
       "8.62684E+17       2795       -0.500000       neg        True   \n",
       "8.62685E+17       2795        0.500000       pos        True   \n",
       "8.62685E+17       2795        0.433333       pos        True   \n",
       "8.62699E+17       2795        0.100000       pos        True   \n",
       "8.62721E+17       2795        0.500000       pos        True   \n",
       "8.62729E+17       2795        0.200000       pos        True   \n",
       "8.62733E+17       2795        0.200000       pos        True   \n",
       "8.62795E+17       2795        0.600000       pos        True   \n",
       "8.62798E+17       2795        0.800000       pos        True   \n",
       "8.62802E+17       2795        0.500000       pos        True   \n",
       "8.62826E+17       2795        0.300000       pos        True   \n",
       "8.62827E+17       2795       -1.000000       neg        True   \n",
       "8.62834E+17       2795        0.100000       pos        True   \n",
       "8.62866E+17       2795        0.050000       pos        True   \n",
       "8.62889E+17       2795        0.650000       pos        True   \n",
       "8.62909E+17       2795       -0.500000       neg        True   \n",
       "\n",
       "                                                                         sub_assessments  \\\n",
       "tweet_id                                                                                   \n",
       "8.51485E+17                                                          [(ecological, 0.4)]   \n",
       "8.55009E+17                                               [(clear, 0.10000000000000002)]   \n",
       "8.55012E+17                                                           [(horrible, -1.0)]   \n",
       "8.61559E+17                                              [(latest, 0.5), (deadly, -0.2)]   \n",
       "8.61566E+17                                               [(down, -0.15555555555555559)]   \n",
       "8.6157E+17                                                           [(very real, 0.26)]   \n",
       "8.61574E+17                                               [(down, -0.15555555555555559)]   \n",
       "8.61575E+17  [(illegal, -0.5), (straight, 0.2), (bad, -0.6999999999999998), (good, 0.7)]   \n",
       "8.61586E+17                                              [(latest, 0.5), (deadly, -0.2)]   \n",
       "8.61665E+17              [(becoming, 0.45), (more, 0.5), (common, -0.3), (deadly, -0.2)]   \n",
       "8.61742E+17                                                            [(unique, 0.375)]   \n",
       "8.61953E+17              [(failure, -0.3166666666666667), (latest, 0.5), (deadly, -0.2)]   \n",
       "8.62678E+17                                            [(very good, 0.9099999999999999)]   \n",
       "8.62681E+17                                                        [(very weird, -0.65)]   \n",
       "8.62684E+17                                                              [(wrong, -0.5)]   \n",
       "8.62685E+17                                                              [(latest, 0.5)]   \n",
       "8.62685E+17                              [(latest, 0.5), (most, 0.5), (compelling, 0.3)]   \n",
       "8.62699E+17                                               [(clear, 0.10000000000000002)]   \n",
       "8.62721E+17                                                         [(interesting, 0.5)]   \n",
       "8.62729E+17                                                              [(really, 0.2)]   \n",
       "8.62733E+17                                                                [(real, 0.2)]   \n",
       "8.62795E+17                                               [(greatest, 1.0), (very, 0.2)]   \n",
       "8.62798E+17                                                               [(great, 0.8)]   \n",
       "8.62802E+17                                                                [(many, 0.5)]   \n",
       "8.62826E+17                                                            [(exciting, 0.3)]   \n",
       "8.62827E+17                                                           [(terrible, -1.0)]   \n",
       "8.62834E+17                                                              [(direct, 0.1)]   \n",
       "8.62866E+17                                       [(much more, 0.5), (implicated, -0.4)]   \n",
       "8.62889E+17                                                   [(very interesting, 0.65)]   \n",
       "8.62909E+17                                                         [(vulnerable, -0.5)]   \n",
       "\n",
       "                                obj_assessments  \n",
       "tweet_id                                         \n",
       "8.51485E+17                  [(financial, 0.0)]  \n",
       "8.55009E+17              [(not actually, -0.0)]  \n",
       "8.55012E+17                                  []  \n",
       "8.61559E+17                                  []  \n",
       "8.61566E+17                     [(enough, 0.0)]  \n",
       "8.6157E+17   [(physically, 0.0), (enough, 0.0)]  \n",
       "8.61574E+17                                  []  \n",
       "8.61575E+17                                  []  \n",
       "8.61586E+17                                  []  \n",
       "8.61665E+17                                  []  \n",
       "8.61742E+17                                  []  \n",
       "8.61953E+17                                  []  \n",
       "8.62678E+17                                  []  \n",
       "8.62681E+17                                  []  \n",
       "8.62684E+17                                  []  \n",
       "8.62685E+17                                  []  \n",
       "8.62685E+17                                  []  \n",
       "8.62699E+17                                  []  \n",
       "8.62721E+17                                  []  \n",
       "8.62729E+17                                  []  \n",
       "8.62733E+17                                  []  \n",
       "8.62795E+17                                  []  \n",
       "8.62798E+17                                  []  \n",
       "8.62802E+17                                  []  \n",
       "8.62826E+17                                  []  \n",
       "8.62827E+17                                  []  \n",
       "8.62834E+17                                  []  \n",
       "8.62866E+17                                  []  \n",
       "8.62889E+17                                  []  \n",
       "8.62909E+17                                  []  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores[sentiment_scores['subjective']==True][['tweet_text_url_token', 'content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments', 'obj_assessments']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>Hmmmmmm &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>Hello &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.5502E+17</td>\n",
       "      <td>SOMEBODY hasn't read about prohibition yet. &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61565E+17</td>\n",
       "      <td>&lt;URL&gt; via @</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61571E+17</td>\n",
       "      <td>&lt;URL&gt; #fentanyl #opioidepidemic $BICX</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30509E+17</td>\n",
       "      <td>Comments from Ryder and our automated vehicle technology partner @embarktrucks were featured in this @nytimes story about #AutonomousVehicles and how soon we could expect to regularly see them on the highway. &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(regularly, 0.0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30527E+17</td>\n",
       "      <td>😨\\n&lt;URL&gt; &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.3053E+17</td>\n",
       "      <td>I've got to figure out a way to make money on this transition. &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30573E+17</td>\n",
       "      <td>We’ve been reporting on what FedEx and UPS are investing in. It’s not workers, it’s automation and driverless vehicles. &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30585E+17</td>\n",
       "      <td>When it comes to #selfdriving vehicles, trucks could beat cars to America’s highways: &lt;URL&gt; via @nytimes</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35794 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                               tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                                                                                              \n",
       "8.5501E+17                                                                                                                                                                                                            Hmmmmmm <URL>   \n",
       "8.55015E+17                                                                                                                                                                                                             Hello <URL>   \n",
       "8.5502E+17                                                                                                                                                                        SOMEBODY hasn't read about prohibition yet. <URL>   \n",
       "8.61565E+17                                                                                                                                                                                                             <URL> via @   \n",
       "8.61571E+17                                                                                                                                                                                   <URL> #fentanyl #opioidepidemic $BICX   \n",
       "...                                                                                                                                                                                                                             ...   \n",
       "9.30509E+17  Comments from Ryder and our automated vehicle technology partner @embarktrucks were featured in this @nytimes story about #AutonomousVehicles and how soon we could expect to regularly see them on the highway. <URL>   \n",
       "9.30527E+17                                                                                                                                                                                                          😨\\n<URL> <URL>   \n",
       "9.3053E+17                                                                                                                                                     I've got to figure out a way to make money on this transition. <URL>   \n",
       "9.30573E+17                                                                                           We’ve been reporting on what FedEx and UPS are investing in. It’s not workers, it’s automation and driverless vehicles. <URL>   \n",
       "9.30585E+17                                                                                                                When it comes to #selfdriving vehicles, trucks could beat cars to America’s highways: <URL> via @nytimes   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective sub_assessments  \\\n",
       "tweet_id                                                                       \n",
       "8.5501E+17        2644             0.0       neu       False              []   \n",
       "8.55015E+17       2644             0.0       neu       False              []   \n",
       "8.5502E+17        2644             0.0       neu       False              []   \n",
       "8.61565E+17       1909             0.0       neu       False              []   \n",
       "8.61571E+17       1909             0.0       neu       False              []   \n",
       "...                ...             ...       ...         ...             ...   \n",
       "9.30509E+17       3351             0.0       neu       False              []   \n",
       "9.30527E+17       3351             0.0       neu       False              []   \n",
       "9.3053E+17        3351             0.0       neu       False              []   \n",
       "9.30573E+17       3351             0.0       neu       False              []   \n",
       "9.30585E+17       3351             0.0       neu       False              []   \n",
       "\n",
       "                obj_assessments  \n",
       "tweet_id                         \n",
       "8.5501E+17                   []  \n",
       "8.55015E+17                  []  \n",
       "8.5502E+17                   []  \n",
       "8.61565E+17                  []  \n",
       "8.61571E+17                  []  \n",
       "...                         ...  \n",
       "9.30509E+17  [(regularly, 0.0)]  \n",
       "9.30527E+17                  []  \n",
       "9.3053E+17                   []  \n",
       "9.30573E+17                  []  \n",
       "9.30585E+17                  []  \n",
       "\n",
       "[35794 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores[sentiment_scores['subjective']==False][['tweet_text_url_token','content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments','obj_assessments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_scores[(sentiment_scores['sub']<0.1) & (sentiment_scores['sub_assessments'] != '')][['tweet_text_url_token','sub','sub_assessments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/phanivalasa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/phanivalasa/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def sentiment_analyzer_scores(text):\n",
    "    score = analyzer.polarity_scores(text)['compound']\n",
    "    return score\n",
    "#     print(text)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_sentiment(text):\n",
    "    \n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    \n",
    "    sub_word_list=[]\n",
    "    neu_word_list=[]\n",
    "    \n",
    "    for word in tokenized_text:\n",
    "        score = analyzer.polarity_scores(word)['compound']\n",
    "        if score > 0.05:\n",
    "            tup = (word, score)\n",
    "            sub_word_list.append(tup)\n",
    "        elif score < -0.05:\n",
    "            tup = (word, score)\n",
    "            sub_word_list.append(tup)\n",
    "        else:\n",
    "            neu_word_list.append(word)\n",
    "            \n",
    "#     print('Subjective:',sub_word_list)        \n",
    "#     print('Neutral:',neu_word_list)    \n",
    "    return sub_word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pos = '#Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>'\n",
    "# sentiment_analyzer_scores(text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_word_sentiment(text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets_vader(df):    \n",
    "    column_names = ['tweet_id','content_id','tweet_text_url_token','polarity_score', 'sentiment','subjective',\n",
    "                    'sub_assessments','obj_assessments']\n",
    "    # polarity_score - is the polarity score\n",
    "    # sentiment - pos, neg or neu\n",
    "    # subjective - True/False. True if it's neg or pos.\n",
    "    # sub_assessments - words contributing to pos/neg\n",
    "\n",
    "    return_df = pd.DataFrame()\n",
    "    for idx,row in df.iterrows():\n",
    "        tweet_id = row['tweet_id']\n",
    "        content_id = row['content_id']\n",
    "        tweet_text_url_token = row['tweet_text_url_token']\n",
    "#         sub = TextBlob(row['tweet_text_url_token']).sentiment.subjectivity\n",
    "        polarity_score = sentiment_analyzer_scores(str(row['tweet_text_url_token']))\n",
    "        if (polarity_score>0.05):\n",
    "            sentiment = 'pos'\n",
    "            subjective = True\n",
    "        elif (polarity_score<-0.05):\n",
    "            sentiment = 'neg'\n",
    "            subjective = True\n",
    "        else:\n",
    "            sentiment = 'neu'\n",
    "            subjective = False\n",
    "        sub_assessments = get_word_sentiment(str(row['tweet_text_url_token']))\n",
    "        obj_assessments = ''\n",
    "        return_df = pd.concat([return_df, pd.DataFrame([[tweet_id,content_id,tweet_text_url_token,polarity_score,sentiment,\n",
    "                                                         subjective, sub_assessments,obj_assessments]])],axis=0)\n",
    "    \n",
    "    return_df.columns=column_names\n",
    "    return_df.index =return_df['tweet_id']\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores_vader = process_tweets_vader(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>2736</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(disaster, -0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>-0.8856</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.6157E+17</td>\n",
       "      <td>Very real news. If you can (literally) even physically see the amount of this you are taking, it's enough to kill you &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(kill, -0.6908)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61574E+17</td>\n",
       "      <td>Crack down on opiods and heroin and people start using horse tranquilizers. You have to provide treatment to help. &lt;URL&gt;</td>\n",
       "      <td>1909</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(heroin, -0.4939), (tranquilizers, -0.1027), (help, 0.4019)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30497E+17</td>\n",
       "      <td>Harvey Mudd alumni are impacting #selfdriving auto innovations. Read about '01 engineering alum &amp;amp; @PelotonTech CEO Josh Switkes' work to make trucking safer. &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(safer, 0.4215)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.3051E+17</td>\n",
       "      <td>But not a great headline for truck drivers &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>-0.6642</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(great, 0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30527E+17</td>\n",
       "      <td>😨\\n&lt;URL&gt; &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(😨, -0.4939)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30566E+17</td>\n",
       "      <td>Big increase in investment hastening arrival of driverless trucks – at least in the US #transport #logistics &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(increase, 0.3182)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30571E+17</td>\n",
       "      <td>As readers of &lt;URL&gt; already know thanks to our coverage of UPS, FedEx investments in driverless trucks, drones, and other job-killers... &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(thanks, 0.4404)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54992 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                                               \n",
       "8.51485E+17                                                                                    #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.55009E+17                                                         The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "8.55012E+17                                   (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "8.6157E+17                                               Very real news. If you can (literally) even physically see the amount of this you are taking, it's enough to kill you <URL>   \n",
       "8.61574E+17                                                 Crack down on opiods and heroin and people start using horse tranquilizers. You have to provide treatment to help. <URL>   \n",
       "...                                                                                                                                                                              ...   \n",
       "9.30497E+17  Harvey Mudd alumni are impacting #selfdriving auto innovations. Read about '01 engineering alum &amp; @PelotonTech CEO Josh Switkes' work to make trucking safer. <URL>   \n",
       "9.3051E+17                                                                                                                          But not a great headline for truck drivers <URL>   \n",
       "9.30527E+17                                                                                                                                                           😨\\n<URL> <URL>   \n",
       "9.30566E+17                                                       Big increase in investment hastening arrival of driverless trucks – at least in the US #transport #logistics <URL>   \n",
       "9.30571E+17                           As readers of <URL> already know thanks to our coverage of UPS, FedEx investments in driverless trucks, drones, and other job-killers... <URL>   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective  \\\n",
       "tweet_id                                                       \n",
       "8.51485E+17       2736         -0.6249       neg        True   \n",
       "8.55009E+17       2644          0.7641       pos        True   \n",
       "8.55012E+17       2644         -0.8856       neg        True   \n",
       "8.6157E+17        1909         -0.6908       neg        True   \n",
       "8.61574E+17       1909         -0.2263       neg        True   \n",
       "...                ...             ...       ...         ...   \n",
       "9.30497E+17       3351          0.4215       pos        True   \n",
       "9.3051E+17        3351         -0.6642       neg        True   \n",
       "9.30527E+17       3351         -0.4939       neg        True   \n",
       "9.30566E+17       3351          0.3182       pos        True   \n",
       "9.30571E+17       3351          0.4404       pos        True   \n",
       "\n",
       "                                                                    sub_assessments  \\\n",
       "tweet_id                                                                              \n",
       "8.51485E+17                                                   [(disaster, -0.6249)]   \n",
       "8.55009E+17  [(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]   \n",
       "8.55012E+17            [(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]   \n",
       "8.6157E+17                                                        [(kill, -0.6908)]   \n",
       "8.61574E+17           [(heroin, -0.4939), (tranquilizers, -0.1027), (help, 0.4019)]   \n",
       "...                                                                             ...   \n",
       "9.30497E+17                                                       [(safer, 0.4215)]   \n",
       "9.3051E+17                                                        [(great, 0.6249)]   \n",
       "9.30527E+17                                                          [(😨, -0.4939)]   \n",
       "9.30566E+17                                                    [(increase, 0.3182)]   \n",
       "9.30571E+17                                                      [(thanks, 0.4404)]   \n",
       "\n",
       "            obj_assessments  \n",
       "tweet_id                     \n",
       "8.51485E+17                  \n",
       "8.55009E+17                  \n",
       "8.55012E+17                  \n",
       "8.6157E+17                   \n",
       "8.61574E+17                  \n",
       "...                     ...  \n",
       "9.30497E+17                  \n",
       "9.3051E+17                   \n",
       "9.30527E+17                  \n",
       "9.30566E+17                  \n",
       "9.30571E+17                  \n",
       "\n",
       "[54992 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_vader[sentiment_scores_vader['subjective']==True][['tweet_text_url_token','content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments', 'obj_assessments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    res = nlp.annotate(text,\n",
    "                       properties={'annotators': 'sentiment',\n",
    "                                   'outputFormat': 'json',\n",
    "                                   'timeout': 5000,\n",
    "                       })\n",
    "#     print(text)\n",
    "#     print('Sentiment:', res['sentences'][0]['sentiment'])\n",
    "#     print('Sentiment score:', res['sentences'][0]['sentimentValue'])\n",
    "#     print('Sentiment distribution (0-v. negative, 5-v. positive:', res['sentences'][0]['sentimentDistribution'])\n",
    "    ret = res['sentences'][0]['sentimentValue']\n",
    "\n",
    "    if ret.isdecimal():\n",
    "        ret = int(ret)\n",
    "    else:\n",
    "        print('Non int value - ', ret)\n",
    "        ret = 2\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score_stanford(text):\n",
    "    res = nlp.annotate(text,\n",
    "                       properties={'annotators': 'sentiment',\n",
    "                                   'outputFormat': 'json',\n",
    "                                   'timeout': 5000,\n",
    "                       })\n",
    "    \n",
    "    count = 0\n",
    "    score = 0\n",
    "    \n",
    "    try:         \n",
    "        for s in res[\"sentences\"]:\n",
    "            count += 1\n",
    "            sc = int(s[\"sentimentValue\"])\n",
    "            score = score + sc\n",
    "    #         print(\"{}: '{}': {} (Sentiment Value) {} (Sentiment)\".format(\n",
    "    #             s[\"index\"],\n",
    "    #             \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "    #             s[\"sentimentValue\"], s[\"sentiment\"]))\n",
    "\n",
    "        ret = score/count\n",
    "    except:\n",
    "        print('failed text is - ', text)\n",
    "        ret = 2\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets_stanford_nlp(df):    \n",
    "    column_names = ['tweet_id','content_id','tweet_text_url_token','polarity_score', 'sentiment','subjective',\n",
    "                    'sub_assessments','obj_assessments']\n",
    "    # polarity_score - is the polarity score\n",
    "    # sentiment - pos, neg or neu\n",
    "    # subjective - True/False. True if it's neg or pos.\n",
    "    # sub_assessments - words contributing to pos/neg\n",
    "\n",
    "    return_df = pd.DataFrame()\n",
    "    for idx,row in df.iterrows():\n",
    "        tweet_id = row['tweet_id']\n",
    "        content_id = row['content_id']\n",
    "        tweet_text_url_token = row['tweet_text_url_token']\n",
    "#         sub = TextBlob(row['tweet_text_url_token']).sentiment.subjectivity\n",
    "        polarity_score = get_sentiment_score_stanford(str(row['tweet_text_url_token']))\n",
    "        if (polarity_score<2):\n",
    "            sentiment = 'neg'\n",
    "            subjective = True\n",
    "        elif (polarity_score>2):\n",
    "            sentiment = 'pos'\n",
    "            subjective = True\n",
    "        else:\n",
    "            sentiment = 'neu'\n",
    "            subjective = False\n",
    "        sub_assessments = ''\n",
    "        obj_assessments = ''\n",
    "        return_df = pd.concat([return_df, pd.DataFrame([[tweet_id,content_id,tweet_text_url_token,polarity_score,sentiment,\n",
    "                                                         subjective, sub_assessments,obj_assessments]])],axis=0)\n",
    "    \n",
    "    return_df.columns=column_names\n",
    "    return_df.index =return_df['tweet_id']\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores_stanford = process_tweets_stanford_nlp(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>2736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.5502E+17</td>\n",
       "      <td>SOMEBODY hasn't read about prohibition yet. &lt;URL&gt;</td>\n",
       "      <td>2644</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.61566E+17</td>\n",
       "      <td>\"When it comes to cracking down on opioids, just going after the drug’s supply isn’t enough.\" &lt;URL&gt; by @germanrlopez</td>\n",
       "      <td>1909</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30554E+17</td>\n",
       "      <td>In the past year, self-driving &amp;amp; other trucking technologies have seen more than $1 billion in investments &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30562E+17</td>\n",
       "      <td>@theitskeptic Yet more cherry-picking... &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30571E+17</td>\n",
       "      <td>As readers of &lt;URL&gt; already know thanks to our coverage of UPS, FedEx investments in driverless trucks, drones, and other job-killers... &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30573E+17</td>\n",
       "      <td>We’ve been reporting on what FedEx and UPS are investing in. It’s not workers, it’s automation and driverless vehicles. &lt;URL&gt;</td>\n",
       "      <td>3351</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30585E+17</td>\n",
       "      <td>When it comes to #selfdriving vehicles, trucks could beat cars to America’s highways: &lt;URL&gt; via @nytimes</td>\n",
       "      <td>3351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57835 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                      \n",
       "8.51485E+17                                                           #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.55009E+17                                The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "8.55012E+17          (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "8.5502E+17                                                                                                SOMEBODY hasn't read about prohibition yet. <URL>   \n",
       "8.61566E+17                            \"When it comes to cracking down on opioids, just going after the drug’s supply isn’t enough.\" <URL> by @germanrlopez   \n",
       "...                                                                                                                                                     ...   \n",
       "9.30554E+17                            In the past year, self-driving &amp; other trucking technologies have seen more than $1 billion in investments <URL>   \n",
       "9.30562E+17                                                                                                  @theitskeptic Yet more cherry-picking... <URL>   \n",
       "9.30571E+17  As readers of <URL> already know thanks to our coverage of UPS, FedEx investments in driverless trucks, drones, and other job-killers... <URL>   \n",
       "9.30573E+17                   We’ve been reporting on what FedEx and UPS are investing in. It’s not workers, it’s automation and driverless vehicles. <URL>   \n",
       "9.30585E+17                                        When it comes to #selfdriving vehicles, trucks could beat cars to America’s highways: <URL> via @nytimes   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective sub_assessments  \\\n",
       "tweet_id                                                                       \n",
       "8.51485E+17       2736        1.000000       neg        True                   \n",
       "8.55009E+17       2644        1.000000       neg        True                   \n",
       "8.55012E+17       2644        1.800000       neg        True                   \n",
       "8.5502E+17        2644        1.500000       neg        True                   \n",
       "8.61566E+17       1909        1.500000       neg        True                   \n",
       "...                ...             ...       ...         ...             ...   \n",
       "9.30554E+17       3351        1.000000       neg        True                   \n",
       "9.30562E+17       3351        1.000000       neg        True                   \n",
       "9.30571E+17       3351        1.000000       neg        True                   \n",
       "9.30573E+17       3351        1.333333       neg        True                   \n",
       "9.30585E+17       3351        1.000000       neg        True                   \n",
       "\n",
       "            obj_assessments  \n",
       "tweet_id                     \n",
       "8.51485E+17                  \n",
       "8.55009E+17                  \n",
       "8.55012E+17                  \n",
       "8.5502E+17                   \n",
       "8.61566E+17                  \n",
       "...                     ...  \n",
       "9.30554E+17                  \n",
       "9.30562E+17                  \n",
       "9.30571E+17                  \n",
       "9.30573E+17                  \n",
       "9.30585E+17                  \n",
       "\n",
       "[57835 rows x 7 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_stanford[sentiment_scores_stanford['subjective']==True][['tweet_text_url_token', 'content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments', 'obj_assessments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_id    25343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_vader[sentiment_scores_vader['subjective']==False][['content_id']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/harish-cu/tweet-url-relationships/master/data/processed/article_topics_6.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_topics = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>Policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    topic\n",
       "content_id               \n",
       "60                 Policy\n",
       "61                 Policy\n",
       "66                Economy\n",
       "80                 Policy\n",
       "82          Public Health"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = raw_topics[['content_id','topic']]\n",
    "topics = topics.set_index(['content_id'])\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read News Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles = pd.read_csv(\"../data/raw/knight_data_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Fox News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Fox News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Fox News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>The New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           content_source_desc\n",
       "content_id                    \n",
       "60                    Fox News\n",
       "61                    Fox News\n",
       "66                    Fox News\n",
       "80          The New York Times\n",
       "82                         Vox"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = raw_articles[['content_id','content_source_desc']]\n",
    "articles = articles.set_index(['content_id'])\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Mean ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings = pd.read_csv(\"../data/raw/knight_data_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_scale_response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating_scale_response\n",
       "content_id                       \n",
       "60                           5.00\n",
       "61                           4.50\n",
       "66                           3.50\n",
       "80                           3.75\n",
       "82                           3.50"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings_blind = raw_ratings[raw_ratings['blind']==1][['content_id','rating_scale_response']]\n",
    "blind_ratings = raw_ratings_blind.groupby(['content_id']).mean()\n",
    "# blind_ratings['content_id1'] = blind_ratings.index\n",
    "blind_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Articles Source and Mean Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ratings = articles.join(blind_ratings)\n",
    "articles_ratings_topics = articles_ratings.join(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ratings['content_id'] = articles_ratings.index\n",
    "articles_ratings['content_id_idx'] = articles_ratings.index\n",
    "articles_ratings = articles_ratings.set_index('content_id_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>rating_scale_response</th>\n",
       "      <th>content_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>5.00</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>4.50</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3.50</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>3.75</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.50</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               content_source_desc  rating_scale_response  content_id\n",
       "content_id_idx                                                       \n",
       "60                        Fox News                   5.00          60\n",
       "61                        Fox News                   4.50          61\n",
       "66                        Fox News                   3.50          66\n",
       "80              The New York Times                   3.75          80\n",
       "82                             Vox                   3.50          82"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ratings_topics['content_id'] = articles_ratings_topics.index\n",
    "articles_ratings_topics['content_id_idx'] = articles_ratings_topics.index\n",
    "articles_ratings_topics = articles_ratings_topics.set_index('content_id_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>rating_scale_response</th>\n",
       "      <th>topic</th>\n",
       "      <th>content_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Policy</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Policy</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Economy</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Policy</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               content_source_desc  rating_scale_response          topic  \\\n",
       "content_id_idx                                                             \n",
       "60                        Fox News                   5.00         Policy   \n",
       "61                        Fox News                   4.50         Policy   \n",
       "66                        Fox News                   3.50        Economy   \n",
       "80              The New York Times                   3.75         Policy   \n",
       "82                             Vox                   3.50  Public Health   \n",
       "\n",
       "                content_id  \n",
       "content_id_idx              \n",
       "60                      60  \n",
       "61                      61  \n",
       "66                      66  \n",
       "80                      80  \n",
       "82                      82  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_ratings_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_scale_response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_source_desc</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100 Percent Fed Up</td>\n",
       "      <td>2.242219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>3.524466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Breitbart</td>\n",
       "      <td>2.525192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fox News</td>\n",
       "      <td>3.253773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Media Matters</td>\n",
       "      <td>2.559345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rating_scale_response\n",
       "content_source_desc                         \n",
       "100 Percent Fed Up                  2.242219\n",
       "Associated Press News               3.524466\n",
       "Breitbart                           2.525192\n",
       "Fox News                            3.253773\n",
       "Media Matters                       2.559345"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_rating = articles_ratings_topics[['content_source_desc','rating_scale_response']].groupby(['content_source_desc']).mean()\n",
    "source_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_scale_response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Economy</td>\n",
       "      <td>3.209807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Policy</td>\n",
       "      <td>3.179498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Politics</td>\n",
       "      <td>3.080381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Public Health</td>\n",
       "      <td>3.595236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Scandal</td>\n",
       "      <td>3.038835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rating_scale_response\n",
       "topic                               \n",
       "Economy                     3.209807\n",
       "Policy                      3.179498\n",
       "Politics                    3.080381\n",
       "Public Health               3.595236\n",
       "Scandal                     3.038835"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_rating = articles_ratings_topics[['topic','rating_scale_response']].groupby(['topic']).mean()\n",
    "topic_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Analysis\n",
    "#### Merge Additional details in Sentiment score dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ratings_topics['content_id'] = articles_ratings_topics['content_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader = pd.merge(sentiment_scores_vader,articles_ratings_topics, on='content_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>rating_scale_response</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>2736</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(disaster, -0.6249)]</td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]</td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hmmmmmm &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>-0.8856</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]</td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hello &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id content_id  \\\n",
       "0  8.51485E+17       2736   \n",
       "1  8.55009E+17       2644   \n",
       "2   8.5501E+17       2644   \n",
       "3  8.55012E+17       2644   \n",
       "4  8.55015E+17       2644   \n",
       "\n",
       "                                                                                                                     tweet_text_url_token  \\\n",
       "0                                                   #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "1                        The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "2                                                                                                                           Hmmmmmm <URL>   \n",
       "3  (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "4                                                                                                                             Hello <URL>   \n",
       "\n",
       "   polarity_score sentiment  subjective  \\\n",
       "0         -0.6249       neg        True   \n",
       "1          0.7641       pos        True   \n",
       "2          0.0000       neu       False   \n",
       "3         -0.8856       neg        True   \n",
       "4          0.0000       neu       False   \n",
       "\n",
       "                                                          sub_assessments  \\\n",
       "0                                                   [(disaster, -0.6249)]   \n",
       "1  [(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]   \n",
       "2                                                                      []   \n",
       "3            [(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]   \n",
       "4                                                                      []   \n",
       "\n",
       "  obj_assessments content_source_desc  rating_scale_response          topic  \n",
       "0                                 Vox               3.615385  Public Health  \n",
       "1                                 Vox               3.421053  Public Health  \n",
       "2                                 Vox               3.421053  Public Health  \n",
       "3                                 Vox               3.421053  Public Health  \n",
       "4                                 Vox               3.421053  Public Health  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader.to_csv('../data/raw/vader_tweet_subjectivity_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vader[['subjective','content_source_desc']].groupby('content_source_desc').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_df(df_sentiment):\n",
    "    \n",
    "    df_analysis_sentiment = pd.DataFrame(columns=['content_source_desc', 'deduped_tweets', 'objective_tweets', 'subjective_tweets', \n",
    "                                            'positive_tweets','negative_tweets','neutral_tweets','trust_mean'])\n",
    "\n",
    "    for index, row in source_rating.iterrows():\n",
    "\n",
    "        df_analysis_sentiment = df_analysis_sentiment.append({'content_source_desc':index, \n",
    "          'deduped_tweets':df_sentiment[(df_sentiment['content_source_desc']==index) ][['subjective']].count()[0], \n",
    "          'objective_tweets':df_sentiment[(df_sentiment['content_source_desc']==index) & (df_sentiment['subjective']==False) ][['subjective']].count()[0], \n",
    "          'subjective_tweets':df_sentiment[(df_sentiment['content_source_desc']==index) & (df_sentiment['subjective']==True) ][['subjective']].count()[0], \n",
    "          'positive_tweets':df_sentiment[(df_sentiment['content_source_desc']==index) & (df_sentiment['sentiment']=='pos') ][['subjective']].count()[0], \n",
    "          'negative_tweets':df_sentiment[(df_sentiment['content_source_desc']==index) & (df_sentiment['sentiment']=='neg') ][['subjective']].count()[0], \n",
    "          'neutral_tweets':df_sentiment[(df_sentiment['content_source_desc']==index) & (df_sentiment['sentiment']=='neu') ][['subjective']].count()[0], \n",
    "          'trust_mean':row['rating_scale_response']}, ignore_index = True)\n",
    "\n",
    "\n",
    "    df_analysis_sentiment['subjective_tweets_proportion'] = df_analysis_sentiment['subjective_tweets']/(df_analysis_sentiment['subjective_tweets']+df_analysis_vader['objective_tweets'])\n",
    "    df_analysis_sentiment['pos/neg Ratio'] = df_analysis_sentiment['positive_tweets']/df_analysis_sentiment['negative_tweets']\n",
    "    \n",
    "    return df_analysis_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_vader = create_source_df(df_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>subjective_tweets_proportion</th>\n",
       "      <th>pos/neg Ratio</th>\n",
       "      <th>trust_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100 Percent Fed Up</td>\n",
       "      <td>1871</td>\n",
       "      <td>0.686799</td>\n",
       "      <td>0.649551</td>\n",
       "      <td>2.242219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>417</td>\n",
       "      <td>0.645084</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>3.524466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>9735</td>\n",
       "      <td>0.675295</td>\n",
       "      <td>0.736856</td>\n",
       "      <td>2.525192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>11711</td>\n",
       "      <td>0.694817</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>3.253773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Media Matters</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.628849</td>\n",
       "      <td>0.637131</td>\n",
       "      <td>2.559345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>43466</td>\n",
       "      <td>0.688653</td>\n",
       "      <td>0.945217</td>\n",
       "      <td>3.527990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Vox</td>\n",
       "      <td>11867</td>\n",
       "      <td>0.675655</td>\n",
       "      <td>0.829758</td>\n",
       "      <td>3.403589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     content_source_desc deduped_tweets subjective_tweets_proportion  \\\n",
       "0     100 Percent Fed Up           1871                     0.686799   \n",
       "1  Associated Press News            417                     0.645084   \n",
       "2              Breitbart           9735                     0.675295   \n",
       "3               Fox News          11711                     0.694817   \n",
       "4          Media Matters           1234                     0.628849   \n",
       "5     The New York Times          43466                     0.688653   \n",
       "6                    Vox          11867                     0.675655   \n",
       "\n",
       "  pos/neg Ratio  trust_mean  \n",
       "0      0.649551    2.242219  \n",
       "1      0.977941    3.524466  \n",
       "2      0.736856    2.525192  \n",
       "3      0.717029    3.253773  \n",
       "4      0.637131    2.559345  \n",
       "5      0.945217    3.527990  \n",
       "6      0.829758    3.403589  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_vader[['content_source_desc','deduped_tweets','subjective_tweets_proportion','pos/neg Ratio','trust_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topic_df(df_sentiment):\n",
    "    \n",
    "    df_analysis_sentiment = pd.DataFrame(columns=['topic', 'deduped_tweets', 'objective_tweets', 'subjective_tweets', \n",
    "                                            'positive_tweets','negative_tweets','neutral_tweets','trust_mean'])\n",
    "\n",
    "    for index, row in topic_rating.iterrows():\n",
    "\n",
    "        df_analysis_sentiment = df_analysis_sentiment.append({'topic':index, \n",
    "          'deduped_tweets':df_sentiment[(df_sentiment['topic']==index) ][['subjective']].count()[0], \n",
    "          'objective_tweets':df_sentiment[(df_sentiment['topic']==index) & (df_sentiment['subjective']==False) ][['subjective']].count()[0], \n",
    "          'subjective_tweets':df_sentiment[(df_sentiment['topic']==index) & (df_sentiment['subjective']==True) ][['subjective']].count()[0], \n",
    "          'positive_tweets':df_sentiment[(df_sentiment['topic']==index) & (df_sentiment['sentiment']=='pos') ][['subjective']].count()[0], \n",
    "          'negative_tweets':df_sentiment[(df_sentiment['topic']==index) & (df_sentiment['sentiment']=='neg') ][['subjective']].count()[0], \n",
    "          'neutral_tweets':df_sentiment[(df_sentiment['topic']==index) & (df_sentiment['sentiment']=='neu') ][['subjective']].count()[0], \n",
    "          'trust_mean':row['rating_scale_response']}, ignore_index = True)\n",
    "\n",
    "\n",
    "    df_analysis_sentiment['subjective_tweets_proportion'] = df_analysis_sentiment['subjective_tweets']/(df_analysis_sentiment['subjective_tweets']+df_analysis_vader['objective_tweets'])\n",
    "    df_analysis_sentiment['pos/neg Ratio'] = df_analysis_sentiment['positive_tweets']/df_analysis_sentiment['negative_tweets']\n",
    "    \n",
    "    return df_analysis_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>subjective_tweets_proportion</th>\n",
       "      <th>pos/neg Ratio</th>\n",
       "      <th>trust_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Economy</td>\n",
       "      <td>1868</td>\n",
       "      <td>0.682385</td>\n",
       "      <td>1.30165</td>\n",
       "      <td>3.209807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Policy</td>\n",
       "      <td>16965</td>\n",
       "      <td>0.988143</td>\n",
       "      <td>0.951582</td>\n",
       "      <td>3.179498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Politics</td>\n",
       "      <td>24359</td>\n",
       "      <td>0.843313</td>\n",
       "      <td>0.772926</td>\n",
       "      <td>3.080381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>15688</td>\n",
       "      <td>0.742841</td>\n",
       "      <td>0.887386</td>\n",
       "      <td>3.595236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Scandal</td>\n",
       "      <td>18966</td>\n",
       "      <td>0.96485</td>\n",
       "      <td>0.746839</td>\n",
       "      <td>3.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2455</td>\n",
       "      <td>0.0991813</td>\n",
       "      <td>1.69439</td>\n",
       "      <td>3.267849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic deduped_tweets subjective_tweets_proportion pos/neg Ratio  \\\n",
       "0        Economy           1868                     0.682385       1.30165   \n",
       "1         Policy          16965                     0.988143      0.951582   \n",
       "2       Politics          24359                     0.843313      0.772926   \n",
       "3  Public Health          15688                     0.742841      0.887386   \n",
       "4        Scandal          18966                      0.96485      0.746839   \n",
       "5     Technology           2455                    0.0991813       1.69439   \n",
       "\n",
       "   trust_mean  \n",
       "0    3.209807  \n",
       "1    3.179498  \n",
       "2    3.080381  \n",
       "3    3.595236  \n",
       "4    3.038835  \n",
       "5    3.267849  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_vader_topic = create_topic_df(df_vader)\n",
    "df_analysis_vader_topic[['topic','deduped_tweets', 'subjective_tweets_proportion', 'pos/neg Ratio','trust_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob Analysis\n",
    "#### Merge Additional details in Sentiment score dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_ratings_topics['content_id'] = articles_ratings_topics['content_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_textblob = pd.merge(sentiment_scores,articles_ratings_topics, on='content_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>rating_scale_response</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>2736</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>0.20</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(ecological, 0.4)]</td>\n",
       "      <td>[(financial, 0.0)]</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>0.05</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.10000000000000002)]</td>\n",
       "      <td>[(not actually, -0.0)]</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hmmmmmm &lt;URL&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(horrible, -1.0)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hello &lt;URL&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id content_id  \\\n",
       "0  8.51485E+17       2736   \n",
       "1  8.55009E+17       2644   \n",
       "2   8.5501E+17       2644   \n",
       "3  8.55012E+17       2644   \n",
       "4  8.55015E+17       2644   \n",
       "\n",
       "                                                                                                                     tweet_text_url_token  \\\n",
       "0                                                   #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "1                        The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "2                                                                                                                           Hmmmmmm <URL>   \n",
       "3  (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "4                                                                                                                             Hello <URL>   \n",
       "\n",
       "   polarity_score sentiment  subjective                 sub_assessments  \\\n",
       "0            0.20       pos        True             [(ecological, 0.4)]   \n",
       "1            0.05       pos        True  [(clear, 0.10000000000000002)]   \n",
       "2            0.00       neu       False                              []   \n",
       "3           -1.00       neg        True              [(horrible, -1.0)]   \n",
       "4            0.00       neu       False                              []   \n",
       "\n",
       "          obj_assessments content_source_desc  rating_scale_response  \\\n",
       "0      [(financial, 0.0)]                 Vox               3.615385   \n",
       "1  [(not actually, -0.0)]                 Vox               3.421053   \n",
       "2                      []                 Vox               3.421053   \n",
       "3                      []                 Vox               3.421053   \n",
       "4                      []                 Vox               3.421053   \n",
       "\n",
       "           topic  \n",
       "0  Public Health  \n",
       "1  Public Health  \n",
       "2  Public Health  \n",
       "3  Public Health  \n",
       "4  Public Health  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textblob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_textblob.to_csv('../data/raw/textblob_tweet_subjectivity_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_textblob = create_source_df(df_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>subjective_tweets_proportion</th>\n",
       "      <th>pos/neg Ratio</th>\n",
       "      <th>trust_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100 Percent Fed Up</td>\n",
       "      <td>1871</td>\n",
       "      <td>0.645278</td>\n",
       "      <td>1.21622</td>\n",
       "      <td>2.242219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>417</td>\n",
       "      <td>0.580737</td>\n",
       "      <td>1.69737</td>\n",
       "      <td>3.524466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>9735</td>\n",
       "      <td>0.615871</td>\n",
       "      <td>1.17791</td>\n",
       "      <td>2.525192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>11711</td>\n",
       "      <td>0.63979</td>\n",
       "      <td>1.10897</td>\n",
       "      <td>3.253773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Media Matters</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.595763</td>\n",
       "      <td>1.1987</td>\n",
       "      <td>2.559345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>43466</td>\n",
       "      <td>0.646593</td>\n",
       "      <td>1.60412</td>\n",
       "      <td>3.527990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Vox</td>\n",
       "      <td>11867</td>\n",
       "      <td>0.629904</td>\n",
       "      <td>1.58933</td>\n",
       "      <td>3.403589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     content_source_desc deduped_tweets subjective_tweets_proportion  \\\n",
       "0     100 Percent Fed Up           1871                     0.645278   \n",
       "1  Associated Press News            417                     0.580737   \n",
       "2              Breitbart           9735                     0.615871   \n",
       "3               Fox News          11711                      0.63979   \n",
       "4          Media Matters           1234                     0.595763   \n",
       "5     The New York Times          43466                     0.646593   \n",
       "6                    Vox          11867                     0.629904   \n",
       "\n",
       "  pos/neg Ratio  trust_mean  \n",
       "0       1.21622    2.242219  \n",
       "1       1.69737    3.524466  \n",
       "2       1.17791    2.525192  \n",
       "3       1.10897    3.253773  \n",
       "4        1.1987    2.559345  \n",
       "5       1.60412    3.527990  \n",
       "6       1.58933    3.403589  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_textblob[['content_source_desc','deduped_tweets','subjective_tweets_proportion','pos/neg Ratio','trust_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>subjective_tweets_proportion</th>\n",
       "      <th>pos/neg Ratio</th>\n",
       "      <th>trust_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Economy</td>\n",
       "      <td>1868</td>\n",
       "      <td>0.648892</td>\n",
       "      <td>2.48232</td>\n",
       "      <td>3.209807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Policy</td>\n",
       "      <td>16965</td>\n",
       "      <td>0.985241</td>\n",
       "      <td>1.53009</td>\n",
       "      <td>3.179498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Politics</td>\n",
       "      <td>24359</td>\n",
       "      <td>0.813135</td>\n",
       "      <td>1.26271</td>\n",
       "      <td>3.080381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>15688</td>\n",
       "      <td>0.705091</td>\n",
       "      <td>1.69558</td>\n",
       "      <td>3.595236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Scandal</td>\n",
       "      <td>18966</td>\n",
       "      <td>0.956674</td>\n",
       "      <td>1.30996</td>\n",
       "      <td>3.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2455</td>\n",
       "      <td>0.0874579</td>\n",
       "      <td>2.27525</td>\n",
       "      <td>3.267849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic deduped_tweets subjective_tweets_proportion pos/neg Ratio  \\\n",
       "0        Economy           1868                     0.648892       2.48232   \n",
       "1         Policy          16965                     0.985241       1.53009   \n",
       "2       Politics          24359                     0.813135       1.26271   \n",
       "3  Public Health          15688                     0.705091       1.69558   \n",
       "4        Scandal          18966                     0.956674       1.30996   \n",
       "5     Technology           2455                    0.0874579       2.27525   \n",
       "\n",
       "   trust_mean  \n",
       "0    3.209807  \n",
       "1    3.179498  \n",
       "2    3.080381  \n",
       "3    3.595236  \n",
       "4    3.038835  \n",
       "5    3.267849  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_textblob_topic = create_topic_df(df_textblob)\n",
    "df_analysis_textblob_topic[['topic','deduped_tweets', 'subjective_tweets_proportion', 'pos/neg Ratio','trust_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford CoreNLP Analysis\n",
    "#### Merge Additional details in Sentiment score dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_ratings_topics['content_id'] = articles_ratings_topics['content_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stanford = pd.merge(sentiment_scores_stanford,articles_ratings_topics, on='content_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>rating_scale_response</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>2736</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hmmmmmm &lt;URL&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>1.8</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hello &lt;URL&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>Public Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id content_id  \\\n",
       "0  8.51485E+17       2736   \n",
       "1  8.55009E+17       2644   \n",
       "2   8.5501E+17       2644   \n",
       "3  8.55012E+17       2644   \n",
       "4  8.55015E+17       2644   \n",
       "\n",
       "                                                                                                                     tweet_text_url_token  \\\n",
       "0                                                   #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "1                        The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "2                                                                                                                           Hmmmmmm <URL>   \n",
       "3  (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "4                                                                                                                             Hello <URL>   \n",
       "\n",
       "   polarity_score sentiment  subjective sub_assessments obj_assessments  \\\n",
       "0             1.0       neg        True                                   \n",
       "1             1.0       neg        True                                   \n",
       "2             2.0       neu       False                                   \n",
       "3             1.8       neg        True                                   \n",
       "4             2.0       neu       False                                   \n",
       "\n",
       "  content_source_desc  rating_scale_response          topic  \n",
       "0                 Vox               3.615385  Public Health  \n",
       "1                 Vox               3.421053  Public Health  \n",
       "2                 Vox               3.421053  Public Health  \n",
       "3                 Vox               3.421053  Public Health  \n",
       "4                 Vox               3.421053  Public Health  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stanford.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stanford.to_csv('../data/raw/stanford_tweet_subjectivity_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_stanford = create_source_df(df_stanford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>subjective_tweets_proportion</th>\n",
       "      <th>pos/neg Ratio</th>\n",
       "      <th>trust_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100 Percent Fed Up</td>\n",
       "      <td>1871</td>\n",
       "      <td>0.694951</td>\n",
       "      <td>0.164921</td>\n",
       "      <td>2.242219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>417</td>\n",
       "      <td>0.68172</td>\n",
       "      <td>0.205323</td>\n",
       "      <td>3.524466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>9735</td>\n",
       "      <td>0.687525</td>\n",
       "      <td>0.156853</td>\n",
       "      <td>2.525192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>11711</td>\n",
       "      <td>0.699512</td>\n",
       "      <td>0.156841</td>\n",
       "      <td>3.253773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Media Matters</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.650915</td>\n",
       "      <td>0.213068</td>\n",
       "      <td>2.559345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>43466</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>3.527990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Vox</td>\n",
       "      <td>11867</td>\n",
       "      <td>0.689997</td>\n",
       "      <td>0.210541</td>\n",
       "      <td>3.403589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     content_source_desc deduped_tweets subjective_tweets_proportion  \\\n",
       "0     100 Percent Fed Up           1871                     0.694951   \n",
       "1  Associated Press News            417                      0.68172   \n",
       "2              Breitbart           9735                     0.687525   \n",
       "3               Fox News          11711                     0.699512   \n",
       "4          Media Matters           1234                     0.650915   \n",
       "5     The New York Times          43466                       0.6994   \n",
       "6                    Vox          11867                     0.689997   \n",
       "\n",
       "  pos/neg Ratio  trust_mean  \n",
       "0      0.164921    2.242219  \n",
       "1      0.205323    3.524466  \n",
       "2      0.156853    2.525192  \n",
       "3      0.156841    3.253773  \n",
       "4      0.213068    2.559345  \n",
       "5      0.199002    3.527990  \n",
       "6      0.210541    3.403589  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_stanford[['content_source_desc','deduped_tweets','subjective_tweets_proportion','pos/neg Ratio','trust_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>subjective_tweets_proportion</th>\n",
       "      <th>pos/neg Ratio</th>\n",
       "      <th>trust_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Economy</td>\n",
       "      <td>1868</td>\n",
       "      <td>0.699179</td>\n",
       "      <td>0.20318</td>\n",
       "      <td>3.209807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Policy</td>\n",
       "      <td>16965</td>\n",
       "      <td>0.988375</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>3.179498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Politics</td>\n",
       "      <td>24359</td>\n",
       "      <td>0.846486</td>\n",
       "      <td>0.183299</td>\n",
       "      <td>3.080381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>15688</td>\n",
       "      <td>0.760616</td>\n",
       "      <td>0.223575</td>\n",
       "      <td>3.595236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Scandal</td>\n",
       "      <td>18966</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.164493</td>\n",
       "      <td>3.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2455</td>\n",
       "      <td>0.112183</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>3.267849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic deduped_tweets subjective_tweets_proportion pos/neg Ratio  \\\n",
       "0        Economy           1868                     0.699179       0.20318   \n",
       "1         Policy          16965                     0.988375      0.178735   \n",
       "2       Politics          24359                     0.846486      0.183299   \n",
       "3  Public Health          15688                     0.760616      0.223575   \n",
       "4        Scandal          18966                     0.966936      0.164493   \n",
       "5     Technology           2455                     0.112183      0.280899   \n",
       "\n",
       "   trust_mean  \n",
       "0    3.209807  \n",
       "1    3.179498  \n",
       "2    3.080381  \n",
       "3    3.595236  \n",
       "4    3.038835  \n",
       "5    3.267849  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_stanford_topic = create_topic_df(df_stanford)\n",
    "df_analysis_stanford_topic[['topic','deduped_tweets', 'subjective_tweets_proportion', 'pos/neg Ratio','trust_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER, TEXTBLOB, CORE NLP - Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>VADER Sub Proportion</th>\n",
       "      <th>VADER pos/neg</th>\n",
       "      <th>TEXTBLOB Sub Proportion</th>\n",
       "      <th>TEXTBLOG pos/neg</th>\n",
       "      <th>STANFORD Sub Proportion</th>\n",
       "      <th>Stanford pos/neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100 Percent Fed Up</td>\n",
       "      <td>1871</td>\n",
       "      <td>0.686799</td>\n",
       "      <td>0.649551</td>\n",
       "      <td>0.645278</td>\n",
       "      <td>1.216216</td>\n",
       "      <td>0.694951</td>\n",
       "      <td>0.164921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>417</td>\n",
       "      <td>0.645084</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.580737</td>\n",
       "      <td>1.697368</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.205323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>9735</td>\n",
       "      <td>0.675295</td>\n",
       "      <td>0.736856</td>\n",
       "      <td>0.615871</td>\n",
       "      <td>1.177911</td>\n",
       "      <td>0.687525</td>\n",
       "      <td>0.156853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>11711</td>\n",
       "      <td>0.694817</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.639790</td>\n",
       "      <td>1.108970</td>\n",
       "      <td>0.699512</td>\n",
       "      <td>0.156841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Media Matters</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.628849</td>\n",
       "      <td>0.637131</td>\n",
       "      <td>0.595763</td>\n",
       "      <td>1.198697</td>\n",
       "      <td>0.650915</td>\n",
       "      <td>0.213068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>43466</td>\n",
       "      <td>0.688653</td>\n",
       "      <td>0.945217</td>\n",
       "      <td>0.646593</td>\n",
       "      <td>1.604123</td>\n",
       "      <td>0.699400</td>\n",
       "      <td>0.199002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Vox</td>\n",
       "      <td>11867</td>\n",
       "      <td>0.675655</td>\n",
       "      <td>0.829758</td>\n",
       "      <td>0.629904</td>\n",
       "      <td>1.589328</td>\n",
       "      <td>0.689997</td>\n",
       "      <td>0.210541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     content_source_desc deduped_tweets  VADER Sub Proportion  VADER pos/neg  \\\n",
       "0     100 Percent Fed Up           1871              0.686799       0.649551   \n",
       "1  Associated Press News            417              0.645084       0.977941   \n",
       "2              Breitbart           9735              0.675295       0.736856   \n",
       "3               Fox News          11711              0.694817       0.717029   \n",
       "4          Media Matters           1234              0.628849       0.637131   \n",
       "5     The New York Times          43466              0.688653       0.945217   \n",
       "6                    Vox          11867              0.675655       0.829758   \n",
       "\n",
       "   TEXTBLOB Sub Proportion  TEXTBLOG pos/neg  STANFORD Sub Proportion  \\\n",
       "0                 0.645278          1.216216                 0.694951   \n",
       "1                 0.580737          1.697368                 0.681720   \n",
       "2                 0.615871          1.177911                 0.687525   \n",
       "3                 0.639790          1.108970                 0.699512   \n",
       "4                 0.595763          1.198697                 0.650915   \n",
       "5                 0.646593          1.604123                 0.699400   \n",
       "6                 0.629904          1.589328                 0.689997   \n",
       "\n",
       "   Stanford pos/neg  \n",
       "0          0.164921  \n",
       "1          0.205323  \n",
       "2          0.156853  \n",
       "3          0.156841  \n",
       "4          0.213068  \n",
       "5          0.199002  \n",
       "6          0.210541  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_source = pd.DataFrame(columns=['content_source_desc', 'deduped_tweets', 'VADER Sub Proportion', 'VADER pos/neg', \n",
    "                                        'TEXTBLOB Sub Proportion','TEXTBLOG pos/neg',\n",
    "                                        'STANFORD Sub Proportion','Stanford pos/neg'])\n",
    "\n",
    "\n",
    "for index, row in source_rating.iterrows():\n",
    "#     print(index,df_analysis_vader[df_analysis_vader['content_source_desc']==index].reset_index().at[0,'subjective_tweets_proportion'])\n",
    "\n",
    "    df_analysis_source = df_analysis_source.append({'content_source_desc':index, \n",
    "      'deduped_tweets':df_analysis_vader[df_analysis_vader['content_source_desc']==index].reset_index().at[0,'deduped_tweets'], \n",
    "      'VADER Sub Proportion':df_analysis_vader[df_analysis_vader['content_source_desc']==index].reset_index().at[0,'subjective_tweets_proportion'], \n",
    "      'VADER pos/neg':df_analysis_vader[df_analysis_vader['content_source_desc']==index].reset_index().at[0,'pos/neg Ratio'], \n",
    "      'TEXTBLOB Sub Proportion':df_analysis_textblob[df_analysis_textblob['content_source_desc']==index].reset_index().at[0,'subjective_tweets_proportion'],\n",
    "      'TEXTBLOG pos/neg':df_analysis_textblob[df_analysis_textblob['content_source_desc']==index].reset_index().at[0,'pos/neg Ratio'], \n",
    "      'STANFORD Sub Proportion':df_analysis_stanford[df_analysis_stanford['content_source_desc']==index].reset_index().at[0,'subjective_tweets_proportion'],\n",
    "      'Stanford pos/neg':df_analysis_stanford[df_analysis_stanford['content_source_desc']==index].reset_index().at[0,'pos/neg Ratio']}, \n",
    "                            ignore_index = True)\n",
    "\n",
    "df_analysis_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis_vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>deduped_tweets</th>\n",
       "      <th>VADER Sub Proportion</th>\n",
       "      <th>VADER pos/neg</th>\n",
       "      <th>TEXTBLOB Sub Proportion</th>\n",
       "      <th>TEXTBLOG pos/neg</th>\n",
       "      <th>STANFORD Sub Proportion</th>\n",
       "      <th>Stanford pos/neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Economy</td>\n",
       "      <td>1868</td>\n",
       "      <td>0.682385</td>\n",
       "      <td>1.301645</td>\n",
       "      <td>0.648892</td>\n",
       "      <td>2.482315</td>\n",
       "      <td>0.699179</td>\n",
       "      <td>0.203180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Policy</td>\n",
       "      <td>16965</td>\n",
       "      <td>0.988143</td>\n",
       "      <td>0.951582</td>\n",
       "      <td>0.985241</td>\n",
       "      <td>1.530090</td>\n",
       "      <td>0.988375</td>\n",
       "      <td>0.178735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Politics</td>\n",
       "      <td>24359</td>\n",
       "      <td>0.843313</td>\n",
       "      <td>0.772926</td>\n",
       "      <td>0.813135</td>\n",
       "      <td>1.262708</td>\n",
       "      <td>0.846486</td>\n",
       "      <td>0.183299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>15688</td>\n",
       "      <td>0.742841</td>\n",
       "      <td>0.887386</td>\n",
       "      <td>0.705091</td>\n",
       "      <td>1.695584</td>\n",
       "      <td>0.760616</td>\n",
       "      <td>0.223575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Scandal</td>\n",
       "      <td>18966</td>\n",
       "      <td>0.964850</td>\n",
       "      <td>0.746839</td>\n",
       "      <td>0.956674</td>\n",
       "      <td>1.309959</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.164493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2455</td>\n",
       "      <td>0.099181</td>\n",
       "      <td>1.694394</td>\n",
       "      <td>0.087458</td>\n",
       "      <td>2.275253</td>\n",
       "      <td>0.112183</td>\n",
       "      <td>0.280899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic deduped_tweets  VADER Sub Proportion  VADER pos/neg  \\\n",
       "0        Economy           1868              0.682385       1.301645   \n",
       "1         Policy          16965              0.988143       0.951582   \n",
       "2       Politics          24359              0.843313       0.772926   \n",
       "3  Public Health          15688              0.742841       0.887386   \n",
       "4        Scandal          18966              0.964850       0.746839   \n",
       "5     Technology           2455              0.099181       1.694394   \n",
       "\n",
       "   TEXTBLOB Sub Proportion  TEXTBLOG pos/neg  STANFORD Sub Proportion  \\\n",
       "0                 0.648892          2.482315                 0.699179   \n",
       "1                 0.985241          1.530090                 0.988375   \n",
       "2                 0.813135          1.262708                 0.846486   \n",
       "3                 0.705091          1.695584                 0.760616   \n",
       "4                 0.956674          1.309959                 0.966936   \n",
       "5                 0.087458          2.275253                 0.112183   \n",
       "\n",
       "   Stanford pos/neg  \n",
       "0          0.203180  \n",
       "1          0.178735  \n",
       "2          0.183299  \n",
       "3          0.223575  \n",
       "4          0.164493  \n",
       "5          0.280899  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis_topic = pd.DataFrame(columns=['topic', 'deduped_tweets', 'VADER Sub Proportion', 'VADER pos/neg', \n",
    "                                        'TEXTBLOB Sub Proportion','TEXTBLOG pos/neg',\n",
    "                                        'STANFORD Sub Proportion','Stanford pos/neg'])\n",
    "\n",
    "\n",
    "for index, row in topic_rating.iterrows():\n",
    "#     print(index,df_analysis_vader[df_analysis_vader['topic']==index].reset_index().at[0,'subjective_tweets_proportion'])\n",
    "\n",
    "    df_analysis_topic = df_analysis_topic.append({'topic':index, \n",
    "      'deduped_tweets':df_analysis_vader_topic[df_analysis_vader_topic['topic']==index].reset_index().at[0,'deduped_tweets'], \n",
    "      'VADER Sub Proportion':df_analysis_vader_topic[df_analysis_vader_topic['topic']==index].reset_index().at[0,'subjective_tweets_proportion'], \n",
    "      'VADER pos/neg':df_analysis_vader_topic[df_analysis_vader_topic['topic']==index].reset_index().at[0,'pos/neg Ratio'], \n",
    "      'TEXTBLOB Sub Proportion':df_analysis_textblob_topic[df_analysis_textblob_topic['topic']==index].reset_index().at[0,'subjective_tweets_proportion'],\n",
    "      'TEXTBLOG pos/neg':df_analysis_textblob_topic[df_analysis_textblob_topic['topic']==index].reset_index().at[0,'pos/neg Ratio'], \n",
    "      'STANFORD Sub Proportion':df_analysis_stanford_topic[df_analysis_stanford_topic['topic']==index].reset_index().at[0,'subjective_tweets_proportion'],\n",
    "      'Stanford pos/neg':df_analysis_stanford_topic[df_analysis_stanford_topic['topic']==index].reset_index().at[0,'pos/neg Ratio']}, \n",
    "                            ignore_index = True)\n",
    "\n",
    "\n",
    "df_analysis_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>2736</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(disaster, -0.6249)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62834E+17</td>\n",
       "      <td>\"After hundreds and hundreds of studies in thousands of children\" ... &amp;lt;amateurish statement lacking scientific process &amp;amp; direct evidence&amp;gt; &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[(gt, 0.2732)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                                 \n",
       "8.51485E+17                                                                      #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.62834E+17  \"After hundreds and hundreds of studies in thousands of children\" ... &lt;amateurish statement lacking scientific process &amp; direct evidence&gt; <URL>   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective  \\\n",
       "tweet_id                                                       \n",
       "8.51485E+17       2736         -0.6249       neg        True   \n",
       "8.62834E+17       2795          0.0000       neu       False   \n",
       "\n",
       "                   sub_assessments  \n",
       "tweet_id                            \n",
       "8.51485E+17  [(disaster, -0.6249)]  \n",
       "8.62834E+17         [(gt, 0.2732)]  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_vader[ (sentiment_scores_vader['tweet_id']=='8.51485E+17') | (sentiment_scores_vader['tweet_id']=='8.62834E+17')][['tweet_text_url_token', 'content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>2736</td>\n",
       "      <td>0.2</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(ecological, 0.4)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62834E+17</td>\n",
       "      <td>\"After hundreds and hundreds of studies in thousands of children\" ... &amp;lt;amateurish statement lacking scientific process &amp;amp; direct evidence&amp;gt; &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.1</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(direct, 0.1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                                 \n",
       "8.51485E+17                                                                      #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.62834E+17  \"After hundreds and hundreds of studies in thousands of children\" ... &lt;amateurish statement lacking scientific process &amp; direct evidence&gt; <URL>   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective  \\\n",
       "tweet_id                                                       \n",
       "8.51485E+17       2736             0.2       pos        True   \n",
       "8.62834E+17       2795             0.1       pos        True   \n",
       "\n",
       "                 sub_assessments  \n",
       "tweet_id                          \n",
       "8.51485E+17  [(ecological, 0.4)]  \n",
       "8.62834E+17      [(direct, 0.1)]  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores[ (sentiment_scores['tweet_id']=='8.51485E+17') | (sentiment_scores['tweet_id']=='8.62834E+17')][['tweet_text_url_token', 'content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>content_id</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>2736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.62834E+17</td>\n",
       "      <td>\"After hundreds and hundreds of studies in thousands of children\" ... &amp;lt;amateurish statement lacking scientific process &amp;amp; direct evidence&amp;gt; &lt;URL&gt;</td>\n",
       "      <td>2795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                                 \n",
       "8.51485E+17                                                                      #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.62834E+17  \"After hundreds and hundreds of studies in thousands of children\" ... &lt;amateurish statement lacking scientific process &amp; direct evidence&gt; <URL>   \n",
       "\n",
       "            content_id  polarity_score sentiment  subjective sub_assessments  \n",
       "tweet_id                                                                      \n",
       "8.51485E+17       2736             1.0       neg        True                  \n",
       "8.62834E+17       2795             1.0       neg        True                  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_stanford[ (sentiment_scores_stanford['tweet_id']=='8.51485E+17') | (sentiment_scores_stanford['tweet_id']=='8.62834E+17')][['tweet_text_url_token', 'content_id',\n",
    "                                                        'polarity_score', 'sentiment','subjective',\n",
    "                                                        'sub_assessments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>2736</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(disaster, -0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hmmmmmm &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>-0.8856</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hello &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id content_id  \\\n",
       "tweet_id                              \n",
       "8.51485E+17  8.51485E+17       2736   \n",
       "8.55009E+17  8.55009E+17       2644   \n",
       "8.5501E+17    8.5501E+17       2644   \n",
       "8.55012E+17  8.55012E+17       2644   \n",
       "8.55015E+17  8.55015E+17       2644   \n",
       "\n",
       "                                                                                                                               tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                              \n",
       "8.51485E+17                                                   #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.55009E+17                        The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "8.5501E+17                                                                                                                            Hmmmmmm <URL>   \n",
       "8.55012E+17  (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "8.55015E+17                                                                                                                             Hello <URL>   \n",
       "\n",
       "             polarity_score sentiment  subjective  \\\n",
       "tweet_id                                            \n",
       "8.51485E+17         -0.6249       neg        True   \n",
       "8.55009E+17          0.7641       pos        True   \n",
       "8.5501E+17           0.0000       neu       False   \n",
       "8.55012E+17         -0.8856       neg        True   \n",
       "8.55015E+17          0.0000       neu       False   \n",
       "\n",
       "                                                                    sub_assessments  \\\n",
       "tweet_id                                                                              \n",
       "8.51485E+17                                                   [(disaster, -0.6249)]   \n",
       "8.55009E+17  [(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]   \n",
       "8.5501E+17                                                                       []   \n",
       "8.55012E+17            [(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]   \n",
       "8.55015E+17                                                                      []   \n",
       "\n",
       "            obj_assessments  \n",
       "tweet_id                     \n",
       "8.51485E+17                  \n",
       "8.55009E+17                  \n",
       "8.5501E+17                   \n",
       "8.55012E+17                  \n",
       "8.55015E+17                  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>8.51485E+17</td>\n",
       "      <td>2736</td>\n",
       "      <td>#Trump’s border wall would be an ecological and financial disaster for the U.S. &lt;URL&gt;</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(disaster, -0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>8.55009E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>The research and experts are clear: Tougher border security measures do not actually stop drug trafficking &lt;URL&gt;</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>8.5501E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hmmmmmm &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>8.55012E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>(psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) &lt;URL&gt;</td>\n",
       "      <td>-0.8856</td>\n",
       "      <td>neg</td>\n",
       "      <td>True</td>\n",
       "      <td>[(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>8.55015E+17</td>\n",
       "      <td>2644</td>\n",
       "      <td>Hello &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30562E+17</td>\n",
       "      <td>9.30562E+17</td>\n",
       "      <td>3351</td>\n",
       "      <td>@theitskeptic Yet more cherry-picking... &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30566E+17</td>\n",
       "      <td>9.30566E+17</td>\n",
       "      <td>3351</td>\n",
       "      <td>Big increase in investment hastening arrival of driverless trucks – at least in the US #transport #logistics &lt;URL&gt;</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(increase, 0.3182)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30571E+17</td>\n",
       "      <td>9.30571E+17</td>\n",
       "      <td>3351</td>\n",
       "      <td>As readers of &lt;URL&gt; already know thanks to our coverage of UPS, FedEx investments in driverless trucks, drones, and other job-killers... &lt;URL&gt;</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>pos</td>\n",
       "      <td>True</td>\n",
       "      <td>[(thanks, 0.4404)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30573E+17</td>\n",
       "      <td>9.30573E+17</td>\n",
       "      <td>3351</td>\n",
       "      <td>We’ve been reporting on what FedEx and UPS are investing in. It’s not workers, it’s automation and driverless vehicles. &lt;URL&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9.30585E+17</td>\n",
       "      <td>9.30585E+17</td>\n",
       "      <td>3351</td>\n",
       "      <td>When it comes to #selfdriving vehicles, trucks could beat cars to America’s highways: &lt;URL&gt; via @nytimes</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80467 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id content_id  \\\n",
       "tweet_id                              \n",
       "8.51485E+17  8.51485E+17       2736   \n",
       "8.55009E+17  8.55009E+17       2644   \n",
       "8.5501E+17    8.5501E+17       2644   \n",
       "8.55012E+17  8.55012E+17       2644   \n",
       "8.55015E+17  8.55015E+17       2644   \n",
       "...                  ...        ...   \n",
       "9.30562E+17  9.30562E+17       3351   \n",
       "9.30566E+17  9.30566E+17       3351   \n",
       "9.30571E+17  9.30571E+17       3351   \n",
       "9.30573E+17  9.30573E+17       3351   \n",
       "9.30585E+17  9.30585E+17       3351   \n",
       "\n",
       "                                                                                                                                       tweet_text_url_token  \\\n",
       "tweet_id                                                                                                                                                      \n",
       "8.51485E+17                                                           #Trump’s border wall would be an ecological and financial disaster for the U.S. <URL>   \n",
       "8.55009E+17                                The research and experts are clear: Tougher border security measures do not actually stop drug trafficking <URL>   \n",
       "8.5501E+17                                                                                                                                    Hmmmmmm <URL>   \n",
       "8.55012E+17          (psst! It was never about drugs. It's always been about brown people. They holler DRUGS! to distract from their horrible racism) <URL>   \n",
       "8.55015E+17                                                                                                                                     Hello <URL>   \n",
       "...                                                                                                                                                     ...   \n",
       "9.30562E+17                                                                                                  @theitskeptic Yet more cherry-picking... <URL>   \n",
       "9.30566E+17                              Big increase in investment hastening arrival of driverless trucks – at least in the US #transport #logistics <URL>   \n",
       "9.30571E+17  As readers of <URL> already know thanks to our coverage of UPS, FedEx investments in driverless trucks, drones, and other job-killers... <URL>   \n",
       "9.30573E+17                   We’ve been reporting on what FedEx and UPS are investing in. It’s not workers, it’s automation and driverless vehicles. <URL>   \n",
       "9.30585E+17                                        When it comes to #selfdriving vehicles, trucks could beat cars to America’s highways: <URL> via @nytimes   \n",
       "\n",
       "             polarity_score sentiment  subjective  \\\n",
       "tweet_id                                            \n",
       "8.51485E+17         -0.6249       neg        True   \n",
       "8.55009E+17          0.7641       pos        True   \n",
       "8.5501E+17           0.0000       neu       False   \n",
       "8.55012E+17         -0.8856       neg        True   \n",
       "8.55015E+17          0.0000       neu       False   \n",
       "...                     ...       ...         ...   \n",
       "9.30562E+17          0.0000       neu       False   \n",
       "9.30566E+17          0.3182       pos        True   \n",
       "9.30571E+17          0.4404       pos        True   \n",
       "9.30573E+17          0.0000       neu       False   \n",
       "9.30585E+17          0.0000       neu       False   \n",
       "\n",
       "                                                                    sub_assessments  \\\n",
       "tweet_id                                                                              \n",
       "8.51485E+17                                                   [(disaster, -0.6249)]   \n",
       "8.55009E+17  [(clear, 0.3818), (Tougher, 0.1779), (security, 0.34), (stop, -0.296)]   \n",
       "8.5501E+17                                                                       []   \n",
       "8.55012E+17            [(distract, -0.296), (horrible, -0.5423), (racism, -0.6249)]   \n",
       "8.55015E+17                                                                      []   \n",
       "...                                                                             ...   \n",
       "9.30562E+17                                                                      []   \n",
       "9.30566E+17                                                    [(increase, 0.3182)]   \n",
       "9.30571E+17                                                      [(thanks, 0.4404)]   \n",
       "9.30573E+17                                                                      []   \n",
       "9.30585E+17                                                                      []   \n",
       "\n",
       "            obj_assessments  \n",
       "tweet_id                     \n",
       "8.51485E+17                  \n",
       "8.55009E+17                  \n",
       "8.5501E+17                   \n",
       "8.55012E+17                  \n",
       "8.55015E+17                  \n",
       "...                     ...  \n",
       "9.30562E+17                  \n",
       "9.30566E+17                  \n",
       "9.30571E+17                  \n",
       "9.30573E+17                  \n",
       "9.30585E+17                  \n",
       "\n",
       "[80467 rows x 8 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                80433\n",
       "content_id              80335\n",
       "tweet_text_url_token    80301\n",
       "polarity_score          80467\n",
       "sentiment               80467\n",
       "subjective              80467\n",
       "sub_assessments         80467\n",
       "obj_assessments         80467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_vader.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader = sentiment_scores_vader.set_index('content_id').join(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "      <th>content_source_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout</td>\n",
       "      <td>#Alabamasenate #RoyMooreChildMolestor https://t.co/uTK2zxyAk6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.</td>\n",
       "      <td>#MoronsAreGoverning https://t.co/Iye7UCcyfR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#GNTP Great New Tax Plan &lt;URL&gt; T</td>\n",
       "      <td>This plan is not simple- where are the massive cuts? @realDonaldTrump @GOPSenFinance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#PruittEndsEPA</td>\n",
       "      <td>#CorruptGOP #Idiots https://t.co/8kxn9nT6cS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#SecuredBorders reposted video  attributed to Conservative Tribune</td>\n",
       "      <td>https://t.co/uYeYCUDoCr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NaN</td>\n",
       "      <td>#Alabamasenate #RoyMooreChildMolestor &lt;URL&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NaN</td>\n",
       "      <td>9.29827E+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NaN</td>\n",
       "      <td>HOW IS THIS EVEN POSSIBLE?! WOW! &lt;URL&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NaN</td>\n",
       "      <td>9.29969E+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;URL&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80467 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                              tweet_id  \\\n",
       "content_id                                                                                                                                                                               \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                          #Alabamasenate #RoyMooreChildMolestor https://t.co/uTK2zxyAk6   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                                                 #MoronsAreGoverning https://t.co/Iye7UCcyfR   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                  This plan is not simple- where are the massive cuts? @realDonaldTrump @GOPSenFinance   \n",
       "#PruittEndsEPA                                                                                                                             #CorruptGOP #Idiots https://t.co/8kxn9nT6cS   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                                                                             https://t.co/uYeYCUDoCr   \n",
       "...                                                                                                                                                                                ...   \n",
       "NaN                                                                                                                                        #Alabamasenate #RoyMooreChildMolestor <URL>   \n",
       "NaN                                                                                                                                                                        9.29827E+17   \n",
       "NaN                                                                                                                                             HOW IS THIS EVEN POSSIBLE?! WOW! <URL>   \n",
       "NaN                                                                                                                                                                        9.29969E+17   \n",
       "NaN                                                                                                                                                                              <URL>   \n",
       "\n",
       "                                                                                                 tweet_text_url_token  \\\n",
       "content_id                                                                                                              \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                   NaN   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                        NaN   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                                  NaN   \n",
       "#PruittEndsEPA                                                                                                    NaN   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                                NaN   \n",
       "...                                                                                                               ...   \n",
       "NaN                                                                                                               NaN   \n",
       "NaN                                                                                                               NaN   \n",
       "NaN                                                                                                               NaN   \n",
       "NaN                                                                                                               NaN   \n",
       "NaN                                                                                                               NaN   \n",
       "\n",
       "                                                                                                  polarity_score  \\\n",
       "content_id                                                                                                         \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout              0.0   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                   0.0   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                             0.0   \n",
       "#PruittEndsEPA                                                                                               0.0   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                           0.0   \n",
       "...                                                                                                          ...   \n",
       "NaN                                                                                                          0.0   \n",
       "NaN                                                                                                          0.0   \n",
       "NaN                                                                                                          0.0   \n",
       "NaN                                                                                                          0.0   \n",
       "NaN                                                                                                          0.0   \n",
       "\n",
       "                                                                                                 sentiment  \\\n",
       "content_id                                                                                                   \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout        neu   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.             neu   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                       neu   \n",
       "#PruittEndsEPA                                                                                         neu   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                     neu   \n",
       "...                                                                                                    ...   \n",
       "NaN                                                                                                    neu   \n",
       "NaN                                                                                                    neu   \n",
       "NaN                                                                                                    neu   \n",
       "NaN                                                                                                    neu   \n",
       "NaN                                                                                                    neu   \n",
       "\n",
       "                                                                                                  subjective  \\\n",
       "content_id                                                                                                     \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout        False   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.             False   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                       False   \n",
       "#PruittEndsEPA                                                                                         False   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                     False   \n",
       "...                                                                                                      ...   \n",
       "NaN                                                                                                    False   \n",
       "NaN                                                                                                    False   \n",
       "NaN                                                                                                    False   \n",
       "NaN                                                                                                    False   \n",
       "NaN                                                                                                    False   \n",
       "\n",
       "                                                                                                 sub_assessments  \\\n",
       "content_id                                                                                                         \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout               []   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                    []   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                              []   \n",
       "#PruittEndsEPA                                                                                                []   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                            []   \n",
       "...                                                                                                          ...   \n",
       "NaN                                                                                                           []   \n",
       "NaN                                                                                                           []   \n",
       "NaN                                                                                                           []   \n",
       "NaN                                                                                                           []   \n",
       "NaN                                                                                                           []   \n",
       "\n",
       "                                                                                                 obj_assessments  \\\n",
       "content_id                                                                                                         \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                    \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                         \n",
       "#GNTP Great New Tax Plan <URL> T                                                                                   \n",
       "#PruittEndsEPA                                                                                                     \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                                 \n",
       "...                                                                                                          ...   \n",
       "NaN                                                                                                                \n",
       "NaN                                                                                                                \n",
       "NaN                                                                                                                \n",
       "NaN                                                                                                                \n",
       "NaN                                                                                                                \n",
       "\n",
       "                                                                                                 content_source_desc  \n",
       "content_id                                                                                                            \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                  NaN  \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                       NaN  \n",
       "#GNTP Great New Tax Plan <URL> T                                                                                 NaN  \n",
       "#PruittEndsEPA                                                                                                   NaN  \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                               NaN  \n",
       "...                                                                                                              ...  \n",
       "NaN                                                                                                              NaN  \n",
       "NaN                                                                                                              NaN  \n",
       "NaN                                                                                                              NaN  \n",
       "NaN                                                                                                              NaN  \n",
       "NaN                                                                                                              NaN  \n",
       "\n",
       "[80467 rows x 8 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                80433\n",
       "tweet_text_url_token    80301\n",
       "polarity_score          80467\n",
       "sentiment               80467\n",
       "subjective              80467\n",
       "sub_assessments         80467\n",
       "obj_assessments         80467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vader.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader = df_vader.join(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text_url_token</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjective</th>\n",
       "      <th>sub_assessments</th>\n",
       "      <th>obj_assessments</th>\n",
       "      <th>content_source_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout</td>\n",
       "      <td>#Alabamasenate #RoyMooreChildMolestor https://t.co/uTK2zxyAk6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.</td>\n",
       "      <td>#MoronsAreGoverning https://t.co/Iye7UCcyfR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#GNTP Great New Tax Plan &lt;URL&gt; T</td>\n",
       "      <td>This plan is not simple- where are the massive cuts? @realDonaldTrump @GOPSenFinance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#PruittEndsEPA</td>\n",
       "      <td>#CorruptGOP #Idiots https://t.co/8kxn9nT6cS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#SecuredBorders reposted video  attributed to Conservative Tribune</td>\n",
       "      <td>https://t.co/uYeYCUDoCr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                              tweet_id  \\\n",
       "content_id                                                                                                                                                                               \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                          #Alabamasenate #RoyMooreChildMolestor https://t.co/uTK2zxyAk6   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                                                 #MoronsAreGoverning https://t.co/Iye7UCcyfR   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                  This plan is not simple- where are the massive cuts? @realDonaldTrump @GOPSenFinance   \n",
       "#PruittEndsEPA                                                                                                                             #CorruptGOP #Idiots https://t.co/8kxn9nT6cS   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                                                                             https://t.co/uYeYCUDoCr   \n",
       "\n",
       "                                                                                                 tweet_text_url_token  \\\n",
       "content_id                                                                                                              \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                   NaN   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                        NaN   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                                  NaN   \n",
       "#PruittEndsEPA                                                                                                    NaN   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                                NaN   \n",
       "\n",
       "                                                                                                  polarity_score  \\\n",
       "content_id                                                                                                         \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout              0.0   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                   0.0   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                             0.0   \n",
       "#PruittEndsEPA                                                                                               0.0   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                           0.0   \n",
       "\n",
       "                                                                                                 sentiment  \\\n",
       "content_id                                                                                                   \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout        neu   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.             neu   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                       neu   \n",
       "#PruittEndsEPA                                                                                         neu   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                     neu   \n",
       "\n",
       "                                                                                                  subjective  \\\n",
       "content_id                                                                                                     \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout        False   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.             False   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                       False   \n",
       "#PruittEndsEPA                                                                                         False   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                     False   \n",
       "\n",
       "                                                                                                 sub_assessments  \\\n",
       "content_id                                                                                                         \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout               []   \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                    []   \n",
       "#GNTP Great New Tax Plan <URL> T                                                                              []   \n",
       "#PruittEndsEPA                                                                                                []   \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                            []   \n",
       "\n",
       "                                                                                                 obj_assessments  \\\n",
       "content_id                                                                                                         \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                    \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                         \n",
       "#GNTP Great New Tax Plan <URL> T                                                                                   \n",
       "#PruittEndsEPA                                                                                                     \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                                 \n",
       "\n",
       "                                                                                                 content_source_desc  \n",
       "content_id                                                                                                            \n",
       "#CorruptGOP puts thru 4 #Unqualified judges nominated by #Trump. #Alabama gets 1. VoteTheGOPout                  NaN  \n",
       "#CorruptGOP will soon transfer him to a useless position for talking about #ClimateChange.                       NaN  \n",
       "#GNTP Great New Tax Plan <URL> T                                                                                 NaN  \n",
       "#PruittEndsEPA                                                                                                   NaN  \n",
       "#SecuredBorders reposted video  attributed to Conservative Tribune                                               NaN  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_scale_response    1627\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blind_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_source_desc    1914\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic    1914\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ratings = articles.join(blind_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_source_desc      1914\n",
       "rating_scale_response    1627\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_source_desc</th>\n",
       "      <th>rating_scale_response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>Vox</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3381</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3382</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3383</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3384</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              content_source_desc  rating_scale_response\n",
       "content_id                                              \n",
       "60                       Fox News                   5.00\n",
       "61                       Fox News                   4.50\n",
       "66                       Fox News                   3.50\n",
       "80             The New York Times                   3.75\n",
       "82                            Vox                   3.50\n",
       "...                           ...                    ...\n",
       "3380        Associated Press News                   3.50\n",
       "3381        Associated Press News                    NaN\n",
       "3382        Associated Press News                   4.50\n",
       "3383        Associated Press News                   4.75\n",
       "3384        Associated Press News                    NaN\n",
       "\n",
       "[1914 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings = pd.read_csv(\"../data/knight_data_ratings.csv\")\n",
    "raw_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
