{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read articles and Ratings file\n",
    "\n",
    "df_articles_train  = pd.read_csv('Data/latest/articles_train.csv')\n",
    "df_articles_test  = pd.read_csv('Data/latest/articles_test.csv')\n",
    "\n",
    "X_train = df_articles_train['content_body_clean']\n",
    "y_train = df_articles_train['blind_mean_rating']\n",
    "\n",
    "X_test = df_articles_test['content_body_clean']\n",
    "y_test = df_articles_test['blind_mean_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TFHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_en_uncased_L-12_H-768_A-12/1\"\n",
    "bert_layer = hub.KerasLayer(bert_path, trainable=True)\n",
    "# max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file1 = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "bert_tokenizer_tfhub = bert.bert_tokenization.FullTokenizer(vocab_file1, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Huggingface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "bert_tokenizer_transformer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments(sentences):\n",
    "    sentences_segments = []\n",
    "    for sent in sentences:\n",
    "      temp = []\n",
    "      i = 0\n",
    "      for token in sent.split(\" \"):\n",
    "        temp.append(i)\n",
    "        if token == \"[SEP]\":\n",
    "          i += 1\n",
    "      sentences_segments.append(temp)\n",
    "    return sentences_segments\n",
    "\n",
    "def _get_inputs(df,_maxlen,tokenizer,use_keras_pad=False):\n",
    "\n",
    "\n",
    "    maxqnans = np.int((_maxlen-20)/2)\n",
    "    pattern = '[^\\w\\s]+|\\n' # remove everything including newline (|\\n) other than words (\\w) or spaces (\\s)\n",
    "    \n",
    "    sentences = [\"[CLS] \" + \" \".join(tokenizer.tokenize(text)[:maxqnans]) +\" [SEP] \" \n",
    "#               + \" \".join(tokenizer.tokenize(ans)[:maxqnans]) +\" [SEP] \" \n",
    "#               + \" \".join(tokenizer.tokenize(title)[:10]) + \" [SEP] \"\n",
    "#               + \" \".join(tokenizer.tokenize(cat)[:10]) +\" [SEP]\" \n",
    "                for (text) in zip(df.str.replace(pattern, '').values.tolist())\n",
    "                ]\n",
    "              #train.head()[['question_title','question_body','answer','category']].values.tolist()]\n",
    "    \n",
    "\n",
    "    #generate masks\n",
    "    # bert requires a mask for the words which are padded. \n",
    "    # Say for example, maxlen is 100, sentence size is 90. then, [1]*90 + [0]*[100-90]\n",
    "    sentences_mask = [[1]*len(sent.split(\" \"))+[0]*(_maxlen - len(sent.split(\" \"))) for sent in sentences]\n",
    " \n",
    "    #generate input ids  \n",
    "    # if less than max length provided then the words are padded\n",
    "    if use_keras_pad:\n",
    "      sentences_padded = pad_sequences(sentences.split(\" \"), dtype=object, maxlen=10, value='[PAD]',padding='post')\n",
    "    else:\n",
    "      sentences_padded = [sent + \" [PAD]\"*(_maxlen-len(sent.split(\" \"))) if len(sent.split(\" \"))!=_maxlen else sent for sent in sentences ]\n",
    "\n",
    "    sentences_converted = [tokenizer.convert_tokens_to_ids(s.split(\" \")) for s in sentences_padded]\n",
    "    \n",
    "    #generate segments\n",
    "    # for each separation [SEP], a new segment is converted\n",
    "    sentences_segment = _get_segments(sentences_padded)\n",
    "\n",
    "    genLength = set([len(sent.split(\" \")) for sent in sentences_padded])\n",
    "\n",
    "    if _maxlen < 20:\n",
    "      raise Exception(\"max length cannot be less than 20\")\n",
    "    elif len(genLength)!=1: \n",
    "      print(genLength)\n",
    "      raise Exception(\"sentences are not of same size\")\n",
    "\n",
    "\n",
    "\n",
    "    #convert list into tensor integer arrays and return it\n",
    "    #return sentences_converted,sentences_segment, sentences_mask\n",
    "    #return [np.asarray(sentences_converted, dtype=np.int32), \n",
    "    #        np.asarray(sentences_segment, dtype=np.int32), \n",
    "    #        np.asarray(sentences_mask, dtype=np.int32)]\n",
    "    return [tf.cast(sentences_converted,tf.int32), tf.cast(sentences_segment,tf.int32), tf.cast(sentences_mask,tf.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = _get_inputs(df=X_train.head(),tokenizer=bert_tokenizer_transformer,_maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Pre-trained model using Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout,Embedding, LSTM, Bidirectional, Input, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = bert_inputs\n",
    "ytr = np.asarray(y_train)\n",
    "\n",
    "Xte = _get_inputs(X_test.head(),_maxlen=100, tokenizer = bert_tokenizer_transformer )\n",
    "yte = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://github.com/huggingface/transformers/issues/1350\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "token_inputs = Input((MAX_SEQUENCE_LENGTH), dtype=tf.int32, name='input_word_ids')\n",
    "mask_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "seg_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "seq_output,_ = bert_model([token_inputs, mask_inputs, seg_inputs])\n",
    "X = GlobalAveragePooling1D()(seq_output)\n",
    "X = Dense(100, activation='relu')(X)\n",
    "output_= Dense(30, activation='sigmoid', name='output')(X)\n",
    "\n",
    "bert_model2 = Model([token_inputs, mask_inputs, seg_inputs],output_)\n",
    "bert_model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model2.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model2.fit(Xtr,ytr,epochs=1,batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_model2.predict(Xte)\n",
    "result.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
