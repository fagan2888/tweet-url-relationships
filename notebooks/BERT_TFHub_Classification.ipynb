{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-TFHub-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FFAMYDe0QdU",
        "colab_type": "text"
      },
      "source": [
        "BERT Classification Model using TFHUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM0WAhyt0gj2",
        "colab_type": "code",
        "outputId": "ef88732a-ca2c-49ed-bd3e-acee1baa336a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 78kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=a09f36151ea625dfc81af54f2c276dd94289bd34b4de2563125ce10a9818dcc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL7ZtACqYsfy",
        "colab_type": "code",
        "outputId": "d78b6332-54e7-40dc-d12e-306cece0fbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!pip install bert_for_tf2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_for_tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.3MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert_for_tf2) (1.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert_for_tf2) (4.38.0)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=7ffc601a687fbbf5a9d2a2ec8f1500a2fdfaca683146550b7d8823db4a14bbf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=449b517dcc9671b96b7e5b36d32631812d9a05442fde2a8467d95fdf3211c431\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=adb8efbf46937e82f1793d8234d1e67f635ed14a8e9c4d33de66b9db72187cbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XdC_tk4qofz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import bert\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUC1GduCxDc0",
        "colab_type": "code",
        "outputId": "5ed162fc-a909-4f62-c0fc-adac0caa98b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw0sVJpAYbLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J_yb6D9Xjlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERT_URL = 'https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1'\n",
        "# module = hub.load(BERT_URL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dSeptQLe3o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKTxiSgec7q-",
        "colab_type": "text"
      },
      "source": [
        "### Import BERT TFHub model and create a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jND5e05-fU1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_path = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-F7H4pYfF3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_layer = hub.KerasLayer(bert_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS6kjqAHnVuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuohTumfnVxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tokenizer_tfhub = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkbzvbuodDZC",
        "colab_type": "text"
      },
      "source": [
        "### Methods to transform input texts (two columns - Tweet Text & Headline) into BERT compatable form. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjIht5JlzhWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_segments(sentences):\n",
        "    sentences_segments = []\n",
        "    for sent in sentences:\n",
        "      temp = []\n",
        "      i = 0\n",
        "      for token in sent.split(\" \"):\n",
        "        temp.append(i)\n",
        "        if token == \"[SEP]\":\n",
        "          i += 1\n",
        "      sentences_segments.append(temp)\n",
        "    return sentences_segments\n",
        "\n",
        "def _get_inputs(df,_maxlen,tokenizer,use_keras_pad=False, verbose=0):\n",
        "\n",
        "    maxqnans = np.int((_maxlen-20)/2)\n",
        "    pattern = '[^\\w\\s]+|\\n' # remove everything including newline (|\\n) other than words (\\w) or spaces (\\s)\n",
        "    \n",
        "    sentences = [\"[CLS] \" + \" \".join(tokenizer.tokenize(txt)) +\" [SEP] \" \n",
        "              + \" \".join(tokenizer.tokenize(head)) +\" [SEP]\" \n",
        "                for (txt,head) \n",
        "                in \n",
        "              zip(df['Text'].str.replace(pattern, '').values.tolist(),\n",
        "              df['News headline'].str.replace(pattern, '').values.tolist())]\n",
        "   \n",
        "    # print(sentences)\n",
        "    if (verbose > 0):\n",
        "      for i in range(min(len(sentences),3)):\n",
        "        print(sentences[i])\n",
        "      \n",
        "    #generate masks\n",
        "    # bert requires a mask for the words which are padded. \n",
        "    # Say for example, maxlen is 100, sentence size is 90. then, [1]*90 + [0]*[100-90]\n",
        "    sentences_mask = [[1]*len(sent.split(\" \"))+[0]*(_maxlen - len(sent.split(\" \"))) for sent in sentences]\n",
        " \n",
        "    #generate input ids  \n",
        "    # if less than max length provided then the words are padded\n",
        "    if use_keras_pad:\n",
        "      sentences_padded = pad_sequences(sentences.split(\" \"), dtype=object, maxlen=10, value='[PAD]',padding='post')\n",
        "    else:\n",
        "      sentences_padded = [sent + \" [PAD]\"*(_maxlen-len(sent.split(\" \"))) if len(sent.split(\" \"))!=_maxlen else sent for sent in sentences ]\n",
        "\n",
        "    sentences_converted = [tokenizer.convert_tokens_to_ids(s.split(\" \")) for s in sentences_padded]\n",
        "    \n",
        "    #generate segments\n",
        "    # for each separation [SEP], a new segment is converted\n",
        "    sentences_segment = _get_segments(sentences_padded)\n",
        "\n",
        "    genLength = set([len(sent.split(\" \")) for sent in sentences_padded])\n",
        "\n",
        "    if _maxlen < 20:\n",
        "      raise Exception(\"max length cannot be less than 20\")\n",
        "    elif len(genLength)!=1: \n",
        "      print(genLength)\n",
        "      raise Exception(\"sentences are not of same size\")\n",
        "\n",
        "    return [tf.cast(sentences_converted,tf.int32), tf.cast(sentences_segment,tf.int32), tf.cast(sentences_mask,tf.int32)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ity8_xCgFUx",
        "colab_type": "text"
      },
      "source": [
        "### Test method for checking inputs to Bert layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s4NHmkLzhhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_t = pd.DataFrame(columns=['Text', 'News headline'])\n",
        "df_t['Text'] = ['It''s a 45 person, lady.',' It''s the second sentence for testing']\n",
        "df_t['News headline'] = ['The Senate is voting on 23654 a 20-week abortion ban. Opponents say it''s ‚Äúbasically relying on junk science.‚Äù',' Iam the 2nd sentence. And then again the next'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Vnyeg47crs",
        "colab_type": "code",
        "outputId": "2eff5fab-8293-4a21-cfa7-b1554cd97a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df_t"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>News headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Its a 45 person, lady.</td>\n",
              "      <td>The Senate is voting on 23654 a 20-week aborti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Its the second sentence for testing</td>\n",
              "      <td>Iam the 2nd sentence. And then again the next</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Text                                      News headline\n",
              "0                Its a 45 person, lady.  The Senate is voting on 23654 a 20-week aborti...\n",
              "1   Its the second sentence for testing      Iam the 2nd sentence. And then again the next"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITyuwxv47BD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "79305ac5-39cc-4f89-e5e7-9190e3d4937a"
      },
      "source": [
        "bert_inputs = _get_inputs(df_t,tokenizer=bert_tokenizer_tfhub,_maxlen=50, verbose=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] its a 45 person lady [SEP] the senate is voting on 236 ##54 a 20 ##week abortion ban opponents say its au ##bas ##ically relying on junk science ##au [SEP]\n",
            "[CLS] its the second sentence for testing [SEP] ia ##m the 2nd sentence and then again the next [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtjZwInp70SZ",
        "colab_type": "code",
        "outputId": "1805d77b-0015-488f-ca35-f5ecb749da2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "bert_inputs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: id=23038, shape=(2, 50), dtype=int32, numpy=\n",
              " array([[  101,  2049,  1037,  3429,  2711,  3203,   102,  1996,  4001,\n",
              "          2003,  6830,  2006, 23593, 27009,  1037,  2322, 28075, 11324,\n",
              "          7221,  7892,  2360,  2049,  8740, 22083, 15004, 18345,  2006,\n",
              "         18015,  2671,  4887,   102,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2049,  1996,  2117,  6251,  2005,  5604,   102, 24264,\n",
              "          2213,  1996,  3416,  6251,  1998,  2059,  2153,  1996,  2279,\n",
              "           102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0]], dtype=int32)>,\n",
              " <tf.Tensor: id=23039, shape=(2, 50), dtype=int32, numpy=\n",
              " array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2]], dtype=int32)>,\n",
              " <tf.Tensor: id=23040, shape=(2, 50), dtype=int32, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0]], dtype=int32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-uGDRijBxKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8C0G9MwgNV0",
        "colab_type": "text"
      },
      "source": [
        "### Data preprocessing\n",
        "Remove Special Characters  \n",
        "Create Train and test datasets  \n",
        "Convert them to Bert inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpF9_LAbBxTV",
        "colab_type": "code",
        "outputId": "aae1e7c6-095f-48cf-8c38-fdc56c97b80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/harish-cu/tweet-url-relationships/master/data/raw/news-url-data-annotated-4-19-2020.csv"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 14:35:03--  https://raw.githubusercontent.com/harish-cu/tweet-url-relationships/master/data/raw/news-url-data-annotated-4-19-2020.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209597 (205K) [text/plain]\n",
            "Saving to: ‘news-url-data-annotated-4-19-2020.csv.1’\n",
            "\n",
            "\r          news-url-   0%[                    ]       0  --.-KB/s               \rnews-url-data-annot 100%[===================>] 204.68K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-30 14:35:03 (4.80 MB/s) - ‘news-url-data-annotated-4-19-2020.csv.1’ saved [209597/209597]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_uEjAQkBxYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"news-url-data-annotated-4-19-2020.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EudX-gtFBxa_",
        "colab_type": "code",
        "outputId": "460920a4-af5d-4e92-fe33-663f234b971b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>News headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>Ironic @voxdotcom attempts to discredit scienc...</td>\n",
              "      <td>Ironic @voxdotcom attempts to discredit scienc...</td>\n",
              "      <td>The Senate is voting on a 20-week abortion ban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SUBJ-ARTICLE</td>\n",
              "      <td>#reproductiverights #abortionrights https://t....</td>\n",
              "      <td>#reproductiverights #abortionrights https://t....</td>\n",
              "      <td>The Senate is voting on a 20-week abortion ban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>i feel like this issue boils down to at what p...</td>\n",
              "      <td>i feel like this issue boils down to at what p...</td>\n",
              "      <td>The Senate is voting on a 20-week abortion ban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>I stg they just pick a random number from a ha...</td>\n",
              "      <td>I stg they just pick a random number from a ha...</td>\n",
              "      <td>The Senate is voting on a 20-week abortion ban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>Maybe you can't regulate evil, but it sure loo...</td>\n",
              "      <td>Maybe you can't regulate evil, but it sure loo...</td>\n",
              "      <td>The Senate is voting on a 20-week abortion ban...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Label  ...                                      News headline\n",
              "0       COMMENT  ...  The Senate is voting on a 20-week abortion ban...\n",
              "1  SUBJ-ARTICLE  ...  The Senate is voting on a 20-week abortion ban...\n",
              "2       COMMENT  ...  The Senate is voting on a 20-week abortion ban...\n",
              "3       COMMENT  ...  The Senate is voting on a 20-week abortion ban...\n",
              "4       COMMENT  ...  The Senate is voting on a 20-week abortion ban...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ6Zcg_wBxeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuIvox17j0w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text'] = df['Text'].astype(str).apply(preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59TR3cOPj099",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['News headline'] = df['News headline'].astype(str).apply(preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HerKF5wEBxgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df['Label'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaX7DvRfaRy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Label = df.Label.str.rstrip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7-V_S4mXHBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_filtered = df[(df['Label'] != 'QUOTE') & (df['Label'] != 'I am disappointed in twitter censorship https://t.co/vFAEUUv70N') & (df.Label.notnull()) & (df['Label'] != 'COMMENT + RHET')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlaBn27cXI9v",
        "colab_type": "code",
        "outputId": "60dc678b-f90f-4457-b283-2cb3646eb1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_filtered.Label.astype('category').cat.codes.unique()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 7, 1, 5, 8, 2, 4, 6, 3], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eZzMtV3XJBE",
        "colab_type": "code",
        "outputId": "8bbed3a3-cc19-497e-b680-cb34dd7e8992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df_filtered.Label.unique()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['COMMENT', 'SUBJ-ARTICLE', 'DIRECT', 'RHET', 'SUMMARY', 'HEADLINE',\n",
              "       'NON-EN', 'SPAM', 'META'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R8-ijlBbl51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_codes = list(df_filtered.Label.astype('category').cat.codes.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2emnv8Gb3pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = list(df_filtered.Label.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_D-pyvMbtsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_cat = {}\n",
        "for i in range(len(cat_codes)):\n",
        "  dict_cat[cat_codes[i]] = categories[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAkx5i-UcPcW",
        "colab_type": "code",
        "outputId": "e8747dae-7078-4370-ae90-235dffcbaffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "dict_cat"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'COMMENT',\n",
              " 1: 'DIRECT',\n",
              " 2: 'HEADLINE',\n",
              " 3: 'META',\n",
              " 4: 'NON-EN',\n",
              " 5: 'RHET',\n",
              " 6: 'SPAM',\n",
              " 7: 'SUBJ-ARTICLE',\n",
              " 8: 'SUMMARY'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zemePJt-XJDs",
        "colab_type": "code",
        "outputId": "0b224af0-1ef7-452e-ac4f-de04f7c2fa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_filtered['target'] = df_filtered.Label.astype('category').cat.codes"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnTCGlemXJG4",
        "colab_type": "code",
        "outputId": "cd6afd82-a132-4aab-dfe9-bd30dcdd718c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_filtered.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>News headline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>Ironic voxdotcom attempts to discredit science...</td>\n",
              "      <td>Ironic @voxdotcom attempts to discredit scienc...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SUBJ-ARTICLE</td>\n",
              "      <td>reproductiverights abortionrights https t . co...</td>\n",
              "      <td>#reproductiverights #abortionrights https://t....</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>i feel like this issue boils down to at what p...</td>\n",
              "      <td>i feel like this issue boils down to at what p...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>I stg they just pick a random number from a ha...</td>\n",
              "      <td>I stg they just pick a random number from a ha...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COMMENT</td>\n",
              "      <td>Maybe you can t regulate evil , but it sure lo...</td>\n",
              "      <td>Maybe you can't regulate evil, but it sure loo...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Label  ... target\n",
              "0       COMMENT  ...      0\n",
              "1  SUBJ-ARTICLE  ...      7\n",
              "2       COMMENT  ...      0\n",
              "3       COMMENT  ...      0\n",
              "4       COMMENT  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUBDu-ZNXJMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNZEuK4ocWGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_filtered[['Text','News headline']], df_filtered['target'], test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjp98JnVcWJk",
        "colab_type": "code",
        "outputId": "7a9753b2-16e5-4a8f-9132-1668ef4ac5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>News headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>If Twitter thinks talking about abortions is b...</td>\n",
              "      <td>Twitter Blocks Marsha Blackburn Senate Announc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Irony Congress votes on wk abortion ban based ...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>Pregnant women should be able to decide what t...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>. . but HouseGOP is attacking women s health a...</td>\n",
              "      <td>The Senate is voting on a week abortion ban . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>TN will stay Red ! ! https t . co E xjvvUtEO</td>\n",
              "      <td>Twitter Blocks Marsha Blackburn Senate Announc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text                                      News headline\n",
              "526  If Twitter thinks talking about abortions is b...  Twitter Blocks Marsha Blackburn Senate Announc...\n",
              "198  Irony Congress votes on wk abortion ban based ...  The Senate is voting on a week abortion ban . ...\n",
              "218  Pregnant women should be able to decide what t...  The Senate is voting on a week abortion ban . ...\n",
              "160  . . but HouseGOP is attacking women s health a...  The Senate is voting on a week abortion ban . ...\n",
              "581       TN will stay Red ! ! https t . co E xjvvUtEO  Twitter Blocks Marsha Blackburn Senate Announc..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2ag_RvXJPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpN6UXvflTFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f287b1cf-41d9-476d-b0bd-d0fe9c1607e9"
      },
      "source": [
        "bert_inputs = _get_inputs(X_train,tokenizer=bert_tokenizer_tfhub,_maxlen=200, verbose=1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] if twitter thinks talking about abortion ##s is bad they re gonna be shocked when they hear what pp ##act has been up to https t co ty ##q ##f ##q ##k ##l ##wo ##c [SEP] twitter blocks marsh ##a blackburn senate announcement because of her pro life stance [SEP]\n",
            "[CLS] irony congress votes on w ##k abortion ban based on un ##sc ##ient ##ific fetal pain claim lets insurance for m kids ex ##pire https t co vu ##vy ##z ##va ##x ##gy [SEP] the senate is voting on a week abortion ban opponents say it s basically relying on junk science [SEP]\n",
            "[CLS] pregnant women should be able to decide what to with their bodies [SEP] the senate is voting on a week abortion ban opponents say it s basically relying on junk science [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qt5Y1M0k2Bn",
        "colab_type": "text"
      },
      "source": [
        "### Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9bacEVjd5LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_fullyconnected(MAX_SEQUENCE_LENGTH = 200):\n",
        "    \"\"\"add pretrained bert model as a keras layer\"\"\"\n",
        "    input_word_ids = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
        "    input_masks = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
        "    input_segments = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
        "    sout, _word_emb = bert_layer([input_word_ids, input_masks, input_segments])\n",
        "    X= Dense(100, activation='relu')(sout) \n",
        "    X= Dense(64, activation='relu')(X) \n",
        "    # X = GlobalAveragePooling1D()(X)\n",
        "    output_= Dense(len(categories), activation='softmax', name='output')(X)\n",
        "\n",
        "    #model = Model(input_,output_)\n",
        "    model = Model([input_word_ids, input_masks, input_segments],output_)\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhWzStYTd5Ol",
        "colab_type": "code",
        "outputId": "21fc8408-b4ff-460b-e523-a751b125c660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = model1 = build_model_fullyconnected()\n",
        "\n",
        "model1.compile(optimizer = \"adam\",loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=20, verbose=0)\n",
        "cp_save = tf.keras.callbacks.ModelCheckpoint('model-e{epoch:03d}.ckpt', \n",
        "                                             save_best_only=True, monitor='acc', mode='min')\n",
        "\n",
        "history1 = model1.fit(bert_inputs, y_train, epochs=50, verbose=2, \n",
        "                     callbacks=[earlyStopping, cp_save] )\n",
        "                    #  ,validation_split=0.2 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segments (InputLayer)     [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segments[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 100)          76900       keras_layer[6][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 64)           6464        dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 9)            585         dense_31[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,566,190\n",
            "Trainable params: 83,949\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 537 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 463s - loss: 1.6896 - acc: 0.5047\n",
            "Epoch 2/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 456s - loss: 1.4914 - acc: 0.5400\n",
            "Epoch 3/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 463s - loss: 1.4884 - acc: 0.5400\n",
            "Epoch 4/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 460s - loss: 1.4813 - acc: 0.5400\n",
            "Epoch 5/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 463s - loss: 1.4841 - acc: 0.5400\n",
            "Epoch 6/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 463s - loss: 1.4727 - acc: 0.5400\n",
            "Epoch 7/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 463s - loss: 1.4733 - acc: 0.5400\n",
            "Epoch 8/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 457s - loss: 1.4772 - acc: 0.5400\n",
            "Epoch 9/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 458s - loss: 1.4832 - acc: 0.5400\n",
            "Epoch 10/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 457s - loss: 1.4870 - acc: 0.5400\n",
            "Epoch 11/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 463s - loss: 1.4734 - acc: 0.5400\n",
            "Epoch 12/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 468s - loss: 1.4725 - acc: 0.5400\n",
            "Epoch 13/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 468s - loss: 1.4683 - acc: 0.5400\n",
            "Epoch 14/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 480s - loss: 1.4616 - acc: 0.5400\n",
            "Epoch 15/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 481s - loss: 1.4701 - acc: 0.5400\n",
            "Epoch 16/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 480s - loss: 1.4610 - acc: 0.5400\n",
            "Epoch 17/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 477s - loss: 1.4645 - acc: 0.5400\n",
            "Epoch 18/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 481s - loss: 1.4680 - acc: 0.5400\n",
            "Epoch 19/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 481s - loss: 1.4693 - acc: 0.5400\n",
            "Epoch 20/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 479s - loss: 1.4607 - acc: 0.5400\n",
            "Epoch 21/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 487s - loss: 1.4578 - acc: 0.5400\n",
            "Epoch 22/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 490s - loss: 1.4550 - acc: 0.5400\n",
            "Epoch 23/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 484s - loss: 1.4625 - acc: 0.5400\n",
            "Epoch 24/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 484s - loss: 1.4552 - acc: 0.5400\n",
            "Epoch 25/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 489s - loss: 1.4677 - acc: 0.5400\n",
            "Epoch 26/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 485s - loss: 1.4508 - acc: 0.5400\n",
            "Epoch 27/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 486s - loss: 1.4453 - acc: 0.5400\n",
            "Epoch 28/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 487s - loss: 1.4544 - acc: 0.5400\n",
            "Epoch 29/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 488s - loss: 1.4537 - acc: 0.5400\n",
            "Epoch 30/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 488s - loss: 1.4510 - acc: 0.5400\n",
            "Epoch 31/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 493s - loss: 1.4450 - acc: 0.5400\n",
            "Epoch 32/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 493s - loss: 1.4497 - acc: 0.5400\n",
            "Epoch 33/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 494s - loss: 1.4413 - acc: 0.5400\n",
            "Epoch 34/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 492s - loss: 1.4439 - acc: 0.5400\n",
            "Epoch 35/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 487s - loss: 1.4399 - acc: 0.5400\n",
            "Epoch 36/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 490s - loss: 1.4433 - acc: 0.5400\n",
            "Epoch 37/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 491s - loss: 1.4378 - acc: 0.5400\n",
            "Epoch 38/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 484s - loss: 1.4422 - acc: 0.5400\n",
            "Epoch 39/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 483s - loss: 1.4465 - acc: 0.5400\n",
            "Epoch 40/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 478s - loss: 1.4443 - acc: 0.5400\n",
            "Epoch 41/50\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 475s - loss: 1.4406 - acc: 0.5400\n",
            "Epoch 42/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bOYcrgrd5Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvf2fSkyXJR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_bertembed(MAX_SEQUENCE_LENGTH = 200):\n",
        "\n",
        "    input_ = Input(shape = (768), name='bert_enconding')\n",
        "    X= Dense(100, activation='relu')(input_) \n",
        "    X= Dense(64, activation='relu')(X) \n",
        "    # X = GlobalAveragePooling1D()(X)\n",
        "    output_= Dense(len(categories), activation='softmax', name='output')(X)\n",
        "    \n",
        "    model = Model(input_,output_)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1APSbVRf5UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtr_bert,_ = bert_layer(bert_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6odgehZnqGW8",
        "colab_type": "code",
        "outputId": "7c620bed-8565-4d1d-db2d-ae62b0cef996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xtr_bert.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([537, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHZ9vdxhtdWz",
        "colab_type": "code",
        "outputId": "e09e2200-ceab-4c55-abf3-58d0896b9ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = build_model_bertembed()\n",
        "\n",
        "model2.compile(optimizer = \"adam\",loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=100, verbose=0)\n",
        "cp_save = tf.keras.callbacks.ModelCheckpoint('model-e{epoch:03d}.ckpt', \n",
        "                                             save_best_only=True, monitor='acc', mode='min')\n",
        "\n",
        "history2 = model2.fit(Xtr_bert, y_train, epochs=200, verbose=2, \n",
        "                     callbacks=[earlyStopping, cp_save])\n",
        "                      # , validation_split=0.2 )"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert_enconding (InputLayer)  [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               76900     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 9)                 585       \n",
            "=================================================================\n",
            "Total params: 83,949\n",
            "Trainable params: 83,949\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 537 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-e001.ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model-e001.ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "537/537 - 1s - loss: 1.6001 - acc: 0.5121\n",
            "Epoch 2/200\n",
            "537/537 - 0s - loss: 1.5203 - acc: 0.5345\n",
            "Epoch 3/200\n",
            "537/537 - 0s - loss: 1.5394 - acc: 0.5345\n",
            "Epoch 4/200\n",
            "537/537 - 0s - loss: 1.5213 - acc: 0.5345\n",
            "Epoch 5/200\n",
            "537/537 - 0s - loss: 1.5030 - acc: 0.5345\n",
            "Epoch 6/200\n",
            "537/537 - 0s - loss: 1.5061 - acc: 0.5345\n",
            "Epoch 7/200\n",
            "537/537 - 0s - loss: 1.5010 - acc: 0.5345\n",
            "Epoch 8/200\n",
            "537/537 - 0s - loss: 1.4922 - acc: 0.5345\n",
            "Epoch 9/200\n",
            "537/537 - 0s - loss: 1.4982 - acc: 0.5345\n",
            "Epoch 10/200\n",
            "537/537 - 0s - loss: 1.5037 - acc: 0.5345\n",
            "Epoch 11/200\n",
            "537/537 - 0s - loss: 1.4942 - acc: 0.5345\n",
            "Epoch 12/200\n",
            "537/537 - 0s - loss: 1.4898 - acc: 0.5345\n",
            "Epoch 13/200\n",
            "537/537 - 0s - loss: 1.4904 - acc: 0.5345\n",
            "Epoch 14/200\n",
            "537/537 - 0s - loss: 1.5092 - acc: 0.5345\n",
            "Epoch 15/200\n",
            "537/537 - 0s - loss: 1.4973 - acc: 0.5345\n",
            "Epoch 16/200\n",
            "537/537 - 0s - loss: 1.4971 - acc: 0.5345\n",
            "Epoch 17/200\n",
            "537/537 - 0s - loss: 1.4846 - acc: 0.5345\n",
            "Epoch 18/200\n",
            "537/537 - 0s - loss: 1.4823 - acc: 0.5345\n",
            "Epoch 19/200\n",
            "537/537 - 0s - loss: 1.4846 - acc: 0.5345\n",
            "Epoch 20/200\n",
            "537/537 - 0s - loss: 1.4831 - acc: 0.5345\n",
            "Epoch 21/200\n",
            "537/537 - 0s - loss: 1.4869 - acc: 0.5345\n",
            "Epoch 22/200\n",
            "537/537 - 0s - loss: 1.4758 - acc: 0.5345\n",
            "Epoch 23/200\n",
            "537/537 - 0s - loss: 1.4787 - acc: 0.5345\n",
            "Epoch 24/200\n",
            "537/537 - 0s - loss: 1.4763 - acc: 0.5345\n",
            "Epoch 25/200\n",
            "537/537 - 0s - loss: 1.4745 - acc: 0.5345\n",
            "Epoch 26/200\n",
            "537/537 - 0s - loss: 1.4864 - acc: 0.5345\n",
            "Epoch 27/200\n",
            "537/537 - 0s - loss: 1.4757 - acc: 0.5345\n",
            "Epoch 28/200\n",
            "537/537 - 0s - loss: 1.4723 - acc: 0.5345\n",
            "Epoch 29/200\n",
            "537/537 - 0s - loss: 1.4764 - acc: 0.5345\n",
            "Epoch 30/200\n",
            "537/537 - 0s - loss: 1.4743 - acc: 0.5345\n",
            "Epoch 31/200\n",
            "537/537 - 0s - loss: 1.4746 - acc: 0.5345\n",
            "Epoch 32/200\n",
            "537/537 - 0s - loss: 1.4719 - acc: 0.5345\n",
            "Epoch 33/200\n",
            "537/537 - 0s - loss: 1.4707 - acc: 0.5345\n",
            "Epoch 34/200\n",
            "537/537 - 0s - loss: 1.4627 - acc: 0.5345\n",
            "Epoch 35/200\n",
            "537/537 - 0s - loss: 1.4680 - acc: 0.5345\n",
            "Epoch 36/200\n",
            "537/537 - 0s - loss: 1.4636 - acc: 0.5345\n",
            "Epoch 37/200\n",
            "537/537 - 0s - loss: 1.4643 - acc: 0.5345\n",
            "Epoch 38/200\n",
            "537/537 - 0s - loss: 1.4663 - acc: 0.5345\n",
            "Epoch 39/200\n",
            "537/537 - 0s - loss: 1.4691 - acc: 0.5345\n",
            "Epoch 40/200\n",
            "537/537 - 0s - loss: 1.4754 - acc: 0.5345\n",
            "Epoch 41/200\n",
            "537/537 - 0s - loss: 1.4643 - acc: 0.5345\n",
            "Epoch 42/200\n",
            "537/537 - 0s - loss: 1.4651 - acc: 0.5345\n",
            "Epoch 43/200\n",
            "537/537 - 0s - loss: 1.4607 - acc: 0.5345\n",
            "Epoch 44/200\n",
            "537/537 - 0s - loss: 1.4634 - acc: 0.5345\n",
            "Epoch 45/200\n",
            "537/537 - 0s - loss: 1.4645 - acc: 0.5345\n",
            "Epoch 46/200\n",
            "537/537 - 0s - loss: 1.4564 - acc: 0.5345\n",
            "Epoch 47/200\n",
            "537/537 - 0s - loss: 1.4660 - acc: 0.5345\n",
            "Epoch 48/200\n",
            "537/537 - 0s - loss: 1.4628 - acc: 0.5345\n",
            "Epoch 49/200\n",
            "537/537 - 0s - loss: 1.4658 - acc: 0.5345\n",
            "Epoch 50/200\n",
            "537/537 - 0s - loss: 1.4706 - acc: 0.5345\n",
            "Epoch 51/200\n",
            "537/537 - 0s - loss: 1.4824 - acc: 0.5345\n",
            "Epoch 52/200\n",
            "537/537 - 0s - loss: 1.4688 - acc: 0.5345\n",
            "Epoch 53/200\n",
            "537/537 - 0s - loss: 1.4577 - acc: 0.5345\n",
            "Epoch 54/200\n",
            "537/537 - 0s - loss: 1.4577 - acc: 0.5345\n",
            "Epoch 55/200\n",
            "537/537 - 0s - loss: 1.4649 - acc: 0.5345\n",
            "Epoch 56/200\n",
            "537/537 - 0s - loss: 1.4540 - acc: 0.5345\n",
            "Epoch 57/200\n",
            "537/537 - 0s - loss: 1.4713 - acc: 0.5345\n",
            "Epoch 58/200\n",
            "537/537 - 0s - loss: 1.4632 - acc: 0.5345\n",
            "Epoch 59/200\n",
            "537/537 - 0s - loss: 1.4546 - acc: 0.5345\n",
            "Epoch 60/200\n",
            "537/537 - 0s - loss: 1.4640 - acc: 0.5345\n",
            "Epoch 61/200\n",
            "537/537 - 0s - loss: 1.4621 - acc: 0.5345\n",
            "Epoch 62/200\n",
            "537/537 - 0s - loss: 1.4602 - acc: 0.5345\n",
            "Epoch 63/200\n",
            "537/537 - 0s - loss: 1.4582 - acc: 0.5345\n",
            "Epoch 64/200\n",
            "537/537 - 0s - loss: 1.4577 - acc: 0.5345\n",
            "Epoch 65/200\n",
            "537/537 - 0s - loss: 1.4587 - acc: 0.5345\n",
            "Epoch 66/200\n",
            "537/537 - 0s - loss: 1.4531 - acc: 0.5345\n",
            "Epoch 67/200\n",
            "537/537 - 0s - loss: 1.4566 - acc: 0.5345\n",
            "Epoch 68/200\n",
            "537/537 - 0s - loss: 1.4514 - acc: 0.5345\n",
            "Epoch 69/200\n",
            "537/537 - 0s - loss: 1.4587 - acc: 0.5345\n",
            "Epoch 70/200\n",
            "537/537 - 0s - loss: 1.4621 - acc: 0.5345\n",
            "Epoch 71/200\n",
            "537/537 - 0s - loss: 1.4520 - acc: 0.5345\n",
            "Epoch 72/200\n",
            "537/537 - 0s - loss: 1.4519 - acc: 0.5345\n",
            "Epoch 73/200\n",
            "537/537 - 0s - loss: 1.4533 - acc: 0.5345\n",
            "Epoch 74/200\n",
            "537/537 - 0s - loss: 1.4549 - acc: 0.5345\n",
            "Epoch 75/200\n",
            "537/537 - 0s - loss: 1.4561 - acc: 0.5345\n",
            "Epoch 76/200\n",
            "537/537 - 0s - loss: 1.4505 - acc: 0.5345\n",
            "Epoch 77/200\n",
            "537/537 - 0s - loss: 1.4581 - acc: 0.5345\n",
            "Epoch 78/200\n",
            "537/537 - 0s - loss: 1.4650 - acc: 0.5345\n",
            "Epoch 79/200\n",
            "537/537 - 0s - loss: 1.4627 - acc: 0.5345\n",
            "Epoch 80/200\n",
            "537/537 - 0s - loss: 1.4557 - acc: 0.5345\n",
            "Epoch 81/200\n",
            "537/537 - 0s - loss: 1.4618 - acc: 0.5345\n",
            "Epoch 82/200\n",
            "537/537 - 0s - loss: 1.4612 - acc: 0.5345\n",
            "Epoch 83/200\n",
            "537/537 - 0s - loss: 1.4485 - acc: 0.5345\n",
            "Epoch 84/200\n",
            "537/537 - 0s - loss: 1.4450 - acc: 0.5345\n",
            "Epoch 85/200\n",
            "537/537 - 0s - loss: 1.4594 - acc: 0.5345\n",
            "Epoch 86/200\n",
            "537/537 - 0s - loss: 1.4465 - acc: 0.5345\n",
            "Epoch 87/200\n",
            "537/537 - 0s - loss: 1.4656 - acc: 0.5345\n",
            "Epoch 88/200\n",
            "537/537 - 0s - loss: 1.4566 - acc: 0.5345\n",
            "Epoch 89/200\n",
            "537/537 - 0s - loss: 1.4682 - acc: 0.5345\n",
            "Epoch 90/200\n",
            "537/537 - 0s - loss: 1.4568 - acc: 0.5345\n",
            "Epoch 91/200\n",
            "537/537 - 0s - loss: 1.4683 - acc: 0.5345\n",
            "Epoch 92/200\n",
            "537/537 - 0s - loss: 1.4781 - acc: 0.5345\n",
            "Epoch 93/200\n",
            "537/537 - 0s - loss: 1.4661 - acc: 0.5345\n",
            "Epoch 94/200\n",
            "537/537 - 0s - loss: 1.4535 - acc: 0.5345\n",
            "Epoch 95/200\n",
            "537/537 - 0s - loss: 1.4497 - acc: 0.5345\n",
            "Epoch 96/200\n",
            "537/537 - 0s - loss: 1.4556 - acc: 0.5345\n",
            "Epoch 97/200\n",
            "537/537 - 0s - loss: 1.4412 - acc: 0.5345\n",
            "Epoch 98/200\n",
            "537/537 - 0s - loss: 1.4545 - acc: 0.5345\n",
            "Epoch 99/200\n",
            "537/537 - 0s - loss: 1.4471 - acc: 0.5345\n",
            "Epoch 100/200\n",
            "537/537 - 0s - loss: 1.4531 - acc: 0.5345\n",
            "Epoch 101/200\n",
            "537/537 - 0s - loss: 1.4442 - acc: 0.5345\n",
            "Epoch 102/200\n",
            "537/537 - 0s - loss: 1.4434 - acc: 0.5345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IYpj9CStdmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c470180a-9baa-4898-bec3-721333b51f72"
      },
      "source": [
        "test_bert_inputs = _get_inputs(X_test,tokenizer=bert_tokenizer_tfhub,_maxlen=200, verbose=1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] guess we shouldn t be surprised that fake ##ne ##ws liberals prefer to hide the truth https t co w ##dm w ##p ##b r ##j [SEP] twitter blocks marsh ##a blackburn senate announcement because of her pro life stance [SEP]\n",
            "[CLS] ce ##rno ##vich hi ##ck ##field twitter blocks marsh ##a blackburn senate announcement because of her pro life stance https t co o v g ##dy ##r [SEP] twitter blocks marsh ##a blackburn senate announcement because of her pro life stance [SEP]\n",
            "[CLS] doesn t matter now the bill is passed pro ##life https t co p ##x ##oo ##c ##gs ##h z [SEP] the senate is voting on a week abortion ban opponents say it s basically relying on junk science [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQjKXiGbkiu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtst_bert,_ = bert_layer(test_bert_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0YgmPt1mYxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = y_test.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3cLvHjyki0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3a807dd2-f28a-4168-c178-a064d0dba688"
      },
      "source": [
        "model2.evaluate(Xtst_bert, y_test)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r135/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 656us/sample - loss: 1.4256 - acc: 0.5556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.426576895183987, 0.5555556]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2QQSzkokiyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "680121ac-d28b-4f4c-cc59-607d9a16b37f"
      },
      "source": [
        "model2.predict(Xtst_bert[:2])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45591283, 0.12246379, 0.13989314, 0.00906001, 0.01216222,\n",
              "        0.10056213, 0.00885698, 0.06756611, 0.0835228 ],\n",
              "       [0.44960558, 0.11820823, 0.14978886, 0.00860436, 0.01341835,\n",
              "        0.0955203 , 0.00900478, 0.06873979, 0.08710971]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uCuLGlwnqMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPiK6wSDrj9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_labels(np_arr):\n",
        "  return [dict_cat[idx] for idx in list(np_arr)]\n",
        "\n",
        "def prediction_labels(mdl, np_arr):\n",
        "  argmax_output = [np.argmax(lst) for lst in list(mdl.predict(np_arr))]\n",
        "  return return_labels(argmax_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRzvgwXcqwZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "d97d05bd-fbbb-479d-d3cb-9ec6a18ab53a"
      },
      "source": [
        "X_test[:4]"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>News headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>Guess we shouldn t be surprised that fakenews liberals prefer to hide the truth https t . co wdM WPB rJ</td>\n",
              "      <td>Twitter Blocks Marsha Blackburn Senate Announcement Because of Her Pro Life Stance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>Cernovich hickfield Twitter Blocks Marsha Blackburn Senate Announcement Because of Her Pro Life Stance https t . co o v GDYR</td>\n",
              "      <td>Twitter Blocks Marsha Blackburn Senate Announcement Because of Her Pro Life Stance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Doesn t matter now . . . the bill is PASSED ! ProLife https t . co pxOocGSh z</td>\n",
              "      <td>The Senate is voting on a week abortion ban . Opponents say it s basically relying on junk science .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                             Text                                                                                         News headline\n",
              "386                       Guess we shouldn t be surprised that fakenews liberals prefer to hide the truth https t . co wdM WPB rJ                    Twitter Blocks Marsha Blackburn Senate Announcement Because of Her Pro Life Stance\n",
              "457  Cernovich hickfield Twitter Blocks Marsha Blackburn Senate Announcement Because of Her Pro Life Stance https t . co o v GDYR                    Twitter Blocks Marsha Blackburn Senate Announcement Because of Her Pro Life Stance\n",
              "52                                                  Doesn t matter now . . . the bill is PASSED ! ProLife https t . co pxOocGSh z  The Senate is voting on a week abortion ban . Opponents say it s basically relying on junk science ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBA1GHIn7IL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d429486-8700-4a25-ab83-43f455620dc5"
      },
      "source": [
        "print('Actual Label -', return_labels(y_test[:4]))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Label - ['COMMENT', 'HEADLINE', 'COMMENT', 'DIRECT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOdX8Go8sqhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5737db93-8510-413a-b20b-97fd83636d27"
      },
      "source": [
        "print('Predicted Label -', prediction_labels(model2, Xtst_bert[:4]))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Label - ['COMMENT', 'COMMENT', 'COMMENT', 'COMMENT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXxqsuPosfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def convert_sentence_to_features(sentence, tokenizer, max_seq_len):\n",
        "#     tokens = ['[CLS]']\n",
        "#     tokens.extend(tokenizer.tokenize(sentence))\n",
        "#     if len(tokens) > max_seq_len-1:\n",
        "#         tokens = tokens[:max_seq_len-1]\n",
        "#     tokens.append('[SEP]')\n",
        "    \n",
        "#     segment_ids = [0] * len(tokens)\n",
        "#     input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#     input_mask = [1] * len(input_ids)\n",
        "\n",
        "#     #Zero Mask till seq_length\n",
        "#     zero_mask = [0] * (max_seq_len-len(tokens))\n",
        "#     input_ids.extend(zero_mask)\n",
        "#     input_mask.extend(zero_mask)\n",
        "#     segment_ids.extend(zero_mask)\n",
        "    \n",
        "#     return input_ids, input_mask, segment_ids\n",
        "\n",
        "# def convert_sentences_to_features(sentences, tokenizer, max_seq_len=20):\n",
        "#     all_input_ids = []\n",
        "#     all_input_mask = []\n",
        "#     all_segment_ids = []\n",
        "    \n",
        "#     for sentence in sentences:\n",
        "#         input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len)\n",
        "#         all_input_ids.append(input_ids)\n",
        "#         all_input_mask.append(input_mask)\n",
        "#         all_segment_ids.append(segment_ids)\n",
        "    \n",
        "#     return all_input_ids, all_input_mask, all_segment_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seebQdkngDt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}